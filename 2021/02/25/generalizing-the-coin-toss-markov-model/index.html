<!doctype html><html lang="en-US"><head><title>Generalizing the Coin Toss Markov Model - Jim Killingsworth</title><meta charset="utf-8"/><meta name="referrer" content="no-referrer-when-downgrade"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="description" content="This is a continuation of a series of posts on weighted coin toss games. In previous posts, we explored variations of the weighted coin toss game using two, three, and four flips per round. In each variation, the game was described using a Markov model with a fixed number of coin toss events. This post presents a generalized form of the Markov model that can be used to model a game with an arbitrary number of coin toss events. I also show a few examples using a model of the coin toss game with ten flips per round."/><base href="/"/><link rel="canonical" href="https://jkillingsworth.com/2021/02/25/generalizing-the-coin-toss-markov-model/"/><link rel="icon" href="./static/favicon.ico" type="image/x-icon"/><link rel="icon" href="./static/favicon-256.jpg" sizes="256x256"/><link rel="preload" href="./static/fonts/open-sans-v29-latin-700.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v25-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v25-latin-italic.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/roboto-mono-v22-latin-regular.woff2" as="font" crossorigin/><script src="https://www.googletagmanager.com/gtag/js?id=G-KP25LH29N8" async></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag("js", new Date());
  gtag("config", "G-KP25LH29N8");
</script><style>@font-face{font-display:swap;font-family:"Open Sans";font-style:normal;font-weight:700;src:local("Open Sans Bold"),local("OpenSans-Bold"),url(./static/fonts/open-sans-v29-latin-700.woff2) format("woff2"),url(./static/fonts/open-sans-v29-latin-700.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:normal;font-weight:400;src:local("Lora Regular"),local("Lora-Regular"),url(./static/fonts/lora-v25-latin-regular.woff2) format("woff2"),url(./static/fonts/lora-v25-latin-regular.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:italic;font-weight:400;src:local("Lora Italic"),local("Lora-Italic"),url(./static/fonts/lora-v25-latin-italic.woff2) format("woff2"),url(./static/fonts/lora-v25-latin-italic.woff) format("woff")}@font-face{font-display:swap;font-family:"Roboto Mono";font-style:normal;font-weight:400;src:local("Roboto Mono"),local("RobotoMono-Regular"),url(./static/fonts/roboto-mono-v22-latin-regular.woff2) format("woff2"),url(./static/fonts/roboto-mono-v22-latin-regular.woff) format("woff")}
/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:0.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace, monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}
html{box-sizing:border-box;overflow-y:scroll}*,*::before,*::after{box-sizing:inherit}body{font-family:"Lora", "Georgia", serif;font-weight:normal;background:#fff;color:#000;display:flex;flex-flow:row wrap;font-size:12pt;justify-content:space-between;line-height:1.5;margin:0 auto;width:90%}body>*{flex:100%}body>header{font-size:21pt;margin:10px 0}body>footer{border-top:3px solid gray;font-size:10pt;font-style:italic;padding:16px 0}header,nav,h1,h2{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}header a,nav a,h1 a,h2 a{color:inherit}a{color:#0050ff;text-decoration:none}a:hover{color:#0050ff;text-decoration:underline}strong{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}svg{fill:currentColor}.navmenu{border-top:3px solid gray;border-bottom:1px solid #ccc}.navmenu #toggle{float:right;height:24px;margin:4px 0;width:24px}.navmenu #toggle+label{color:transparent;cursor:pointer;display:block;padding:4px 0;position:relative;user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none}.navmenu #toggle+label::before{background:#fff;background-size:24px;content:"";float:right;height:24px;left:24px;position:relative;width:24px}.navmenu #toggle+label::after{content:"Menu";left:0;padding:0 16px;position:absolute}.navmenu #toggle+label{border-bottom:none}.navmenu #toggle+label::before{background-image:url("./static/chevron-down.svg")}.navmenu #toggle+label::after{color:#000}.navmenu #toggle~ul{height:0;visibility:hidden}.navmenu #toggle:checked+label{border-bottom:1px solid #e6e6e6}.navmenu #toggle:checked+label::before{background-image:url("./static/chevron-up.svg")}.navmenu #toggle:checked+label::after{color:gray}.navmenu #toggle:checked~ul{height:auto;visibility:visible}.navmenu ul{display:flex;flex-flow:column wrap;list-style-type:none;justify-content:flex-start;margin:0;overflow:hidden;padding:0}.navmenu ul>li{flex:none}.navmenu ul>li a{display:block;padding:4px 16px}.navmenu ul>li a:hover,.navmenu ul>li a:focus{background:gray;color:#fff}.content{max-width:720px}.content header,.content footer,.content h1,.content h2,.content p,.content ul,.content figure{margin:24px 0}.content h1{font-size:18pt}.content h2{font-size:12pt}.content footer{font-style:italic}.content p:last-of-type::after{clear:both;content:"";display:block}.content ul{padding-left:16px}.content ul>li{margin:12px 0}.content figure{max-width:90vw}.content figure>img{display:block}.content .fig-chart{padding-top:56.25%;page-break-inside:avoid;position:relative}.content .fig-chart>img{max-height:100%;max-width:100%;position:absolute;top:0}.content .fig-latex{overflow-x:auto}.content .fig-latex>img{margin:0 16px}.content .fig-pic-l>img,.content .fig-pic-r>img{margin:0 auto;max-width:100%;object-fit:cover}.content .button{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;background:#e6e6e6;color:inherit;display:block;margin:24px 0;padding:4px 0;text-align:center}.content .button:hover,.content .button:focus{background:gray;color:#fff}.content .message header>h1{background:#ffff60;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .message header>h1::first-letter{text-transform:uppercase}.content .message header>h1::after{content:":"}.content .message p{font-style:italic}.content .newpost header>h1{background:#ffff60;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .newpost header>h1::first-letter{text-transform:uppercase}.content .newpost header>h1::after{content:":"}.content .newpost header>h2{font-size:18pt}.content .newpost a.readmore{background:#e8f0ff}.content .newpost a.readmore::after{content:" \00bb"}.content .newpost a:not(.readmore):not(:hover){color:inherit}.content .oldpost{margin:24px 0}.content .oldpost header>h1{display:none}.content .archive ul>li time{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:none;font-size:10pt}.content .contact label,.content .contact input[type="submit"]{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;cursor:pointer;display:block;margin:16px 0}.content .contact label{margin-bottom:4px}.content .contact input[type="text"],.content .contact input[type="email"],.content .contact textarea{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;line-height:inherit;padding:4px;width:100%}.content .contact textarea{height:200px;max-width:100%;min-width:100%}.content .contact input[type="submit"]{padding:4px 40px}.content .comments{margin:24px 0 8px}.content .comments header>h2{display:none}.content .comments noscript{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;margin:-12px 0 24px}.sidebar header>h1{display:none}.sidebar header>h2{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0}.sidebar section{margin:24px 0}.sidebar section:first-of-type{margin-top:0}.sidebar .social-media ul{list-style:none;padding:0 0 0 16px}.sidebar .social-media ul>li a{display:inline-block}.sidebar .social-media ul>li a *{vertical-align:middle}.sidebar .social-media ul>li a span{margin:0 10px}.sidebar .social-media ul>li a svg{color:gray;height:48px;width:48px}.sidebar .social-media ul>li a:hover svg{color:inherit}.content p:not(.nojustify),.sidebar p:not(.nojustify){text-align:justify;word-spacing:-1px}.content p,.content ul,.sidebar p,.sidebar ul{line-height:1.667}@media only screen and (min-width: 600px){.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{max-width:720px}body>header{font-size:24pt}.navmenu #toggle{display:none}.navmenu #toggle+label{display:none}.navmenu #toggle~ul{height:auto;visibility:visible}.navmenu ul{flex-flow:row wrap}.navmenu ul>li a{padding:4px 32px}}@media only screen and (min-width: 1200px){body{column-gap:60px;max-width:1200px;min-width:1080px}body>header{text-align:center}.content{flex:auto;width:720px}.sidebar{flex:auto}.sidebar section:first-of-type{margin-top:40px}}@media only print{.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{display:block;margin:auto;width:125%}body>header{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0;text-align:left}.content figure{max-width:100%}.navmenu,.sidebar,.oldpost,.comments{display:none}}@page{margin:1in 1.25in}
</style></head><body><header><a href="./">Jim Killingsworth</a></header><nav class="navmenu"><input id="toggle" type="checkbox"/><label for="toggle">Enable menu</label><ul><li><a href="./"> Home </a></li><li><a href="./archive/"> Archive </a></li><li><a href="./about/"> About </a></li><li><a href="./contact/"> Contact </a></li></ul></nav><main class="content"><article><header><h1>Gen­er­al­iz­ing the Coin Toss Markov Mod­el</h1></header><p>This is a con­tin­u­a­tion of a se­ries of posts on weight­ed coin toss games. In pre­vi­ous post­s, we ex­plored vari­a­tions of the weight­ed coin toss game us­ing two, three, and four flips per round. In each vari­a­tion, the game was de­scribed us­ing a Markov mod­el with a fixed num­ber of coin toss events. This post presents a gen­er­al­ized form of the Markov mod­el that can be used to mod­el a game with an ar­bi­trary num­ber of coin toss events. I al­so show a few ex­am­ples us­ing a mod­el of the coin toss game with ten flips per round.</p><h2 id="markov-model-with-2-coin-tosses">Markov Mod­el with 2 Coin Toss­es</h2><p>Let’s start with a very sim­ple mod­el of the coin toss game that us­es on­ly two flips of the coin per round. This is the mod­el used in the pre­vi­ous post ti­tled <a href="/2021/01/29/visualizing-saddle-points-and-minimums/"><em>Vi­su­al­iz­ing Sad­dle Points and Min­i­mums</em></a>. Here is what the Markov mod­el looks like:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-01-latex-2433423379.svg" alt="Figure 1" height="355"></figure><p>In this mod­el, there are five pos­si­ble states that the sys­tem can be in and six pos­si­ble state tran­si­tion­s. Each ar­row rep­re­sents a state tran­si­tion. The state di­a­gram above can be rep­re­sent­ed us­ing a state tran­si­tion ma­trix:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-02-latex-2600938829.svg" alt="Figure 2" height="171"></figure><p>This tran­si­tion ma­trix de­ter­mines the prob­a­bil­i­ty of mov­ing from one state to the nex­t. This is a square ma­trix with a row and a col­umn for each state. The rows rep­re­sent the start­ing states, and the columns rep­re­sent the sub­se­quent states. We can al­so use a vec­tor with five el­e­ments—one for each state—to rep­re­sent the prob­a­bil­i­ty of be­ing in each one of the states at a par­tic­u­lar point in time. Since we al­ways start in the ze­ro state, the ini­tial vec­tor looks like this:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-03-latex-1955742345.svg" alt="Figure 3" height="176"></figure><p>We can com­pute the prob­a­bil­i­ty of be­ing in each one of the five states af­ter the first coin toss by tak­ing the prod­uct of the state vec­tor and the state tran­si­tion ma­trix:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-04-latex-3937244012.svg" alt="Figure 4" height="17"></figure><p>Af­ter the first coin toss, there are two pos­si­ble states that the sys­tem can be in. The prod­uct above works out to the fol­low­ing:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-05-latex-2644020832.svg" alt="Figure 5" height="176"></figure><p>Since there are two flips of the coin per round, we can com­pute the fi­nal out­come dis­tri­b­u­tion by mul­ti­ply­ing the vec­tor above by the tran­si­tion ma­trix one more time:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-06-latex-2174669261.svg" alt="Figure 6" height="17"></figure><p>Af­ter the sec­ond coin toss, there are three pos­si­ble states the sys­tem can be in. The prod­uct above works out to the fol­low­ing:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-07-latex-3633813732.svg" alt="Figure 7" height="177"></figure><p>As you can see, for the fi­nal out­come, the sys­tem can on­ly be in one of three out of the five pos­si­ble states af­ter the sec­ond coin toss. The oth­er two states on­ly serve as in­ter­me­di­ate states that the sys­tem tran­si­tions through. Note that there is a pos­si­bil­i­ty that the sys­tem re­turns to the ini­tial state af­ter the sec­ond coin toss.</p><h2 id="markov-model-with-3-coin-tosses">Markov Mod­el with 3 Coin Toss­es</h2><p>A slight­ly more com­pli­cat­ed mod­el is that of a coin toss game with three flips of the coin per round. This is the mod­el used pre­vi­ous­ly in the post ti­tled <a href="/2020/08/16/visualizing-the-climb-up-the-hill/"><em>Vi­su­al­iz­ing the Climb up the Hill</em></a>. Here is what the Markov mod­el looks like:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-08-latex-3386831867.svg" alt="Figure 8" height="388"></figure><p>In this mod­el, there are sev­en pos­si­ble states that the sys­tem can be in and a to­tal of ten pos­si­ble state tran­si­tion­s. The state di­a­gram il­lus­trat­ed above can be rep­re­sent­ed with the fol­low­ing state tran­si­tion ma­trix:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-09-latex-3133728991.svg" alt="Figure 9" height="248"></figure><p>This is a square ma­trix with sev­en rows and sev­en column­s. We can al­so use a sev­en-ele­ment vec­tor to rep­re­sent the like­li­hood of the sys­tem be­ing in a par­tic­u­lar state at a giv­en point in time. The ini­tial vec­tor looks like this:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-10-latex-3044679043.svg" alt="Figure 10" height="253"></figure><p>We can mul­ti­ply this vec­tor by the tran­si­tion ma­trix three times to de­ter­mine where we might find the state of the sys­tem af­ter three flips of the coin:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-11-latex-4210935829.svg" alt="Figure 11" height="17"></figure><p>Af­ter the third coin toss, there are four pos­si­ble states the sys­tem can be in. The prod­uct above works out to the fol­low­ing:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-12-latex-3995560806.svg" alt="Figure 12" height="253"></figure><p>The sys­tem can be in one of four pos­si­ble states for the fi­nal out­come. The oth­er three states are in­ter­me­di­ate states that the sys­tem tran­si­tions through. No­tice that the ini­tial state is not one of the fi­nal states since there is an odd num­ber of coin toss­es in this case.</p><h2 id="generalized-markov-model">Gen­er­al­ized Markov Mod­el</h2><p>In ad­di­tion to the two Markov mod­els out­lined above, you can al­so find a de­tailed dis­cus­sion of a mod­el of the coin toss game with four flips per round in one of my ear­li­er posts ti­tled <a href="/2019/09/14/estimating-the-weights-of-biased-coins/"><em>Es­ti­mat­ing the Weights of Bi­ased Coins</em></a>. All of these mod­els can be de­scribed by a gen­er­al­ized mod­el. Sup­pose we have a coin toss game with an ar­bi­trary num­ber of flips per round. We can rep­re­sent the gen­er­al­ized form of the Markov mod­el with a state di­a­gram that looks like this:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-13-latex-3386197173.svg" alt="Figure 13" height="388"></figure><p>The to­tal num­ber of states the sys­tem can be in de­pends on the num­ber of coin toss events. We can de­ter­mine the num­ber of states us­ing the fol­low­ing equa­tion:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-14-latex-2908301011.svg" alt="Figure 14" height="87"></figure><p>The num­ber of states the sys­tem can be in de­ter­mines the size of the state tran­si­tion ma­trix. Since this can be an ar­bi­trar­i­ly large ma­trix, it is more prac­ti­cal to de­scribe the con­tents of the ma­trix us­ing an al­go­rith­m:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-15-latex-0827127174.svg" alt="Figure 15" height="504"></figure><p>This is a square ma­trix with a nonze­ro val­ue for every pos­si­ble state tran­si­tion in the Markov mod­el. We al­so need to de­fine an ini­tial state vec­tor. Since there is on­ly one ini­tial state, this vec­tor can be de­scribed with a very sim­ple al­go­rith­m:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-16-latex-2318734012.svg" alt="Figure 16" height="216"></figure><p>Once we have a state tran­si­tion ma­trix and the ini­tial state vec­tor, we can com­pute the fi­nal out­come us­ing the fol­low­ing for­mu­la:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-17-latex-2967125593.svg" alt="Figure 17" height="19"></figure><p>The fi­nal out­come tells us how like­ly it is for each state to be the fi­nal state of the sys­tem af­ter a sin­gle round of the coin toss game. We can al­so rep­re­sent the fi­nal out­come like this:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-18-latex-3854665801.svg" alt="Figure 18" height="201"></figure><p>Each el­e­ment con­tains the prob­a­bil­i­ty that the sys­tem ter­mi­nates in the cor­re­spond­ing state af­ter the fi­nal coin toss. Since our mod­el is sym­met­ric about the ini­tial state, there is a sym­me­try to the re­sult­ing val­ues in the fi­nal out­come.</p><h2 id="equality-constraints">Equal­i­ty Con­straints</h2><p>Giv­en the mod­el of the coin toss game de­scribed above, sup­pose we know the val­ues of the fi­nal out­come but not the val­ues of the weights of the bi­ased coin­s. Start­ing with the fi­nal out­come—some­times re­ferred to as the tar­get dis­tri­b­u­tion—we can find a valid set of weights us­ing the method of La­grange mul­ti­pli­ers de­scribed in <a href="/2020/12/12/equality-constraints-and-lagrange-multipliers/"><em>Equal­i­ty Con­straints and La­grange Mul­ti­pli­ers</em></a>. To use this method, we need to come up with a set of equal­i­ty con­straints based on the mod­el. Let’s start with some equal­i­ty con­di­tions that must hold true:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-19-latex-0476095474.svg" alt="Figure 19" height="63"></figure><p>The left­-hand side of these equa­tions rep­re­sents the val­ue of the known tar­get dis­tri­b­u­tion for the cor­re­spond­ing state. The right-hand side rep­re­sents the com­put­ed re­sult based on the val­ues of the weights of the bi­ased coin­s. These equal­i­ty con­di­tions are true if we have a valid set of weight­s. No­tice al­so the sym­me­try for states above and be­low the ini­tial state. We can leave out the du­pli­cate con­di­tions be­cause they are re­dun­dan­t. We can al­so elim­i­nate states that we know are nev­er ter­mi­nal states. Con­sid­er the fol­low­ing:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-20-latex-1800184409.svg" alt="Figure 20" height="45"></figure><p>These two sets con­tain even and odd num­ber­s, re­spec­tive­ly. We can se­lect one or the oth­er based on whether the num­ber of coin toss events per round is even or odd:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-21-latex-0249595189.svg" alt="Figure 21" height="47"></figure><p>Us­ing the se­lect­ed set, we can de­ter­mine which states are nev­er ter­mi­nal states. Non-ter­mi­nal states have a prob­a­bil­i­ty of ze­ro in the fi­nal out­come. We know the fol­low­ing holds true, no mat­ter what weights are used for the bi­ased coin­s:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-22-latex-3249740944.svg" alt="Figure 22" height="19"></figure><p>We can elim­i­nate non-ter­mi­nal states from con­sid­er­a­tion be­cause they have no bear­ing on the equal­i­ty con­straints need­ed for the method of La­grange mul­ti­pli­er­s. The to­tal num­ber of equal­i­ty con­straints then is giv­en by the fol­low­ing:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-23-latex-4228660138.svg" alt="Figure 23" height="90"></figure><p>The num­ber of equal­i­ty con­straints is a func­tion of the to­tal num­ber of coin toss events. We can es­tab­lish a set of equal­i­ty con­straints like this:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-24-latex-3596642742.svg" alt="Figure 24" height="19"></figure><p>Each con­straint func­tion must be equal to ze­ro. The func­tions we want to use here are func­tions that take the dif­fer­ence be­tween the tar­get val­ues and the com­put­ed val­ues based on a giv­en set of weight­s:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-25-latex-0019630622.svg" alt="Figure 25" height="47"></figure><p>Us­ing these equal­i­ty con­straints, we can con­struct a La­grangian func­tion that can be used to find a valid set of weight­s:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-26-latex-0188879274.svg" alt="Figure 26" height="50"></figure><p>We can use this La­grangian func­tion to find a valid set of weights by ap­ply­ing the op­ti­miza­tion and root-find­ing meth­ods out­lined in pre­vi­ous post­s.</p><h2 id="example-with-exponential-distribution">Ex­am­ple with Ex­po­nen­tial Dis­tri­b­u­tion</h2><p>Now let’s take a look at an ex­am­ple with ten coin toss events per round. Sup­pose we start with the fol­low­ing tar­get dis­tri­b­u­tion:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-27-pmfunc-exponent.svg" alt="Figure 27" height="405" width="720"></figure><p>We want to find a valid set of weights that yields this dis­tri­b­u­tion in the fi­nal out­come. We’ll start with the fol­low­ing ini­tial guess and it­er­a­tive­ly work to­wards a so­lu­tion:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-28-biases-start-slope.svg" alt="Figure 28" height="405" width="720"></figure><p>We can use the mul­ti­vari­ate form of New­ton’s method to find the weights for which the gra­di­ent of the La­grangian func­tion is equal to ze­ro. This method is de­scribed in de­tail in the post ti­tled <a href="/2020/12/31/finding-the-roots-with-newtons-method/"><em>Find­ing the Roots with New­ton’s Method</em></a>. Here we ap­ply the fol­low­ing it­er­a­tive for­mu­la:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-29-latex-1101996698.svg" alt="Figure 29" height="21"></figure><p>Note the use of the al­ter­na­tive no­ta­tion scheme above for the gra­di­ent of the La­grangian func­tion. The La­grangian func­tion we use in this ex­am­ple must have a con­crete de­f­i­n­i­tion of the scor­ing func­tion de­fined. In this ex­am­ple, we use two dif­fer­ent scor­ing func­tion­s, de­fined be­low.</p><p>Here is the de­f­i­n­i­tion of scor­ing func­tion A:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-30-latex-3276289220.svg" alt="Figure 30" height="52"></figure><p>Here is the de­f­i­n­i­tion of scor­ing func­tion B:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-31-latex-0778250660.svg" alt="Figure 31" height="52"></figure><p>Here is the so­lu­tion found us­ing scor­ing func­tion A:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-32-biases-final-1.svg" alt="Figure 32" height="405" width="720"></figure><p>Here is the so­lu­tion found us­ing scor­ing func­tion B:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-33-biases-final-2.svg" alt="Figure 33" height="405" width="720"></figure><p>Here are the num­ber of it­er­a­tions re­quired for each scor­ing func­tion:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-34-latex-3890093899.svg" alt="Figure 34" height="102"></figure><p>In both cas­es, the ini­tial guess is not too far from the op­ti­mal so­lu­tion. As with pre­vi­ous ex­am­ples us­ing New­ton’s method, the sys­tem con­verges in very few it­er­a­tions. Both so­lu­tions are very sim­i­lar, tak­ing on a sort of zigzag shape.</p><h2 id="example-with-triangular-distribution">Ex­am­ple with Tri­an­gu­lar Dis­tri­b­u­tion</h2><p>Let’s take a look at an­oth­er ex­am­ple with ten coin toss events per round. Sup­pose we start with the fol­low­ing tar­get dis­tri­b­u­tion:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-35-pmfunc-triangle.svg" alt="Figure 35" height="405" width="720"></figure><p>We want to find a valid set of weights that yields this dis­tri­b­u­tion in the fi­nal out­come. We’ll start with the fol­low­ing ini­tial guess and it­er­a­tive­ly work to­wards a so­lu­tion:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-36-biases-start-equal.svg" alt="Figure 36" height="405" width="720"></figure><p>To find a valid set of weight­s, we’ll use the mul­ti­vari­ate form of New­ton’s method like we did in the last ex­am­ple. But this time, we’ll in­clude a damp­ing fac­tor to slow down the con­ver­gence. Here is the it­er­a­tive for­mu­la:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-37-latex-0125035537.svg" alt="Figure 37" height="21"></figure><p>We’ll use a damp­ing fac­tor of ten per­cent:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-38-latex-2213068255.svg" alt="Figure 38" height="17"></figure><p>The damp­ing fac­tor slows down the con­ver­gence and pre­vents the method from over­shoot­ing. In this par­tic­u­lar ex­am­ple, the method fails the con­verge with­out slow­ing down the it­er­a­tive process. The use of the damp­ing fac­tor would not be nec­es­sary if we start­ed with an ini­tial guess clos­er to the fi­nal so­lu­tion.</p><p>Here is the so­lu­tion found us­ing scor­ing func­tion A:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-39-biases-final-3.svg" alt="Figure 39" height="405" width="720"></figure><p>Here is the so­lu­tion found us­ing scor­ing func­tion B:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-40-biases-final-4.svg" alt="Figure 40" height="405" width="720"></figure><p>Here are the num­ber of it­er­a­tions re­quired for each scor­ing func­tion:</p><figure class="fig-latex"><img src="./2021/02/25/generalizing-the-coin-toss-markov-model/fig-41-latex-1942193909.svg" alt="Figure 41" height="102"></figure><p>The damped ver­sion of New­ton’s method re­quires many more it­er­a­tions to con­verge than it does with the un­damped ver­sion used in the pre­vi­ous ex­am­ple. As with the pre­vi­ous ex­am­ple, the two so­lu­tions are very sim­i­lar to one an­oth­er, this time tak­ing on a slant­ed shape.</p><h2 id="shortcomings">Short­com­ings</h2><p>The meth­ods used here al­low us to find a valid set of weights for a giv­en tar­get dis­tri­b­u­tion us­ing a mod­el of the coin toss game that al­lows for an ar­bi­trary num­ber of coin toss events. We used the method of La­grange mul­ti­pli­ers to set up an equa­tion, and we used New­ton’s method to solve the equa­tion. But these meth­ods are not with­out their short­com­ings. As we saw in the pre­vi­ous sec­tion, we had to adapt the it­er­a­tive for­mu­la with a damp­ing fac­tor to get the it­er­a­tive process to con­verge to a so­lu­tion.</p><p>Be­sides the over­shoot prob­lem, there are cas­es where these meth­ods might con­verge to a so­lu­tion out­side the ac­cept­able range of val­ues. The weights of the bi­ased coins must al­ways be a prob­a­bil­i­ty be­tween ze­ro and one. There is noth­ing in the method of La­grange mul­ti­pli­ers that lim­its val­ues to a par­tic­u­lar range. I may have to ex­plore an ap­proach us­ing <a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">Karush–Kuh­n–Tuck­er con­di­tions</a> to in­clude in­equal­i­ty con­straints.</p><p>An­oth­er prob­lem is run­time per­for­mance. With the im­ple­men­ta­tion used in this post, find­ing the so­lu­tion for a mod­el with ten coin toss events per round takes a cou­ple of sec­onds to ex­e­cute on my cur­rent hard­ware. A mod­el with one ad­di­tion­al coin toss event per round takes about twice the amount of time to ex­e­cute. This im­ple­men­ta­tion seems to have an ex­po­nen­tial time com­plex­i­ty. There is no par­al­lelis­m, and I have made no at­tempt at per­for­mance tun­ing. But I do think there is room for im­prove­men­t. There might al­so be oth­er ap­proach­es that of­fer a good enough so­lu­tion. Ide­al­ly, I would like to be able to solve for mod­els with twen­ty or even fifty flips per round.</p><p class="nojustify"><a href="https://github.com/jkillingsworth/jkillingsworth.com/tree/master/src/2021-02-25-generalizing-the-coin-toss-markov-model">Ac­com­pa­ny­ing source code is avail­able on GitHub.</a></p><footer><time datetime="2021-02-25">February 25, 2021</time></footer></article><section class="comments"><header><h2>Com­ments</h2></header><script>
    var disqus_config = function () {
      this.page.url = "https://jkillingsworth.com/2021/02/25/generalizing-the-coin-toss-markov-model/";
      this.page.title = "Generalizing the Coin Toss Markov Model";
      this.page.identifier = "/2021/02/25/generalizing-the-coin-toss-markov-model/";
    };
    function disqus_show() {
      var d = document, s = d.createElement("script");
      s.src = "https://jkillingsworth.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    }
    function anchor_blur() {
      var a = document.getElementById("comments");
      a.innerText = "Comments";
      a.blur();
    }
    function disqus() {
      disqus_show();
      anchor_blur();
    }
  </script><a href="javascript:disqus();" id="comments" class="button">Show comments</a><div id="disqus_thread"></div><noscript> Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></section></main><aside class="sidebar"><header><h1>Sidebar</h1></header><section class="social-media"><header><h2>Social Media</h2></header><ul><li><a href="https://www.linkedin.com/in/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M417.2 64H96.8C79.3 64 64 76.6 64 93.9V415c0 17.4 15.3 32.9 32.8 32.9h320.3c17.6 0 30.8-15.6 30.8-32.9V93.9C448 76.6 434.7 64 417.2 64zM183 384h-55V213h55v171zm-25.6-197h-.4c-17.6 0-29-13.1-29-29.5 0-16.7 11.7-29.5 29.7-29.5s29 12.7 29.4 29.5c0 16.4-11.4 29.5-29.7 29.5zM384 384h-55v-93.5c0-22.4-8-37.7-27.9-37.7-15.2 0-24.2 10.3-28.2 20.3-1.5 3.6-1.9 8.5-1.9 13.5V384h-55V213h55v23.8c8-11.4 20.5-27.8 49.6-27.8 36.1 0 63.4 23.8 63.4 75.1V384z"/></svg><span>LinkedIn</span></a></li><li><a href="https://github.com/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9 1.4.3 2.6.4 3.8.4 8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1-8.4 1.9-15.9 2.7-22.6 2.7-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1 10.5 0 20-3.4 25.6-6 2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8 0 0 1.6-.5 5-.5 8.1 0 26.4 3.1 56.6 24.1 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 30.2-21 48.5-24.1 56.6-24.1 3.4 0 5 .5 5 .5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5 1.2 0 2.6-.1 4-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z"/></svg><span>GitHub</span></a></li></ul></section></aside><footer> &copy; 2018&ndash;2022 Jim Killingsworth. All rights reserved. </footer></body></html>