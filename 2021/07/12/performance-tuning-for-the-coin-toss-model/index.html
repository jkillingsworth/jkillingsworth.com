<!doctype html><html lang="en-US"><head><title>Performance Tuning for the Coin Toss Model - Jim Killingsworth</title><meta charset="utf-8"/><meta name="referrer" content="no-referrer-when-downgrade"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="description" content="I wrapped up the last post expressing a desire to study the approximation technique using larger models of the coin toss game. Up until now, I was using a naive implementation of the computation method to perform the calculations—an implementation that was crudely implemented and too slow for larger models. In this post, I demonstrate an alternative approach that has a much better performance profile. I also describe a simple technique that can be used to reduce the number of iterations required when applying the hill climbing algorithm."/><base href="/"/><link rel="canonical" href="https://jkillingsworth.com/2021/07/12/performance-tuning-for-the-coin-toss-model/"/><link rel="icon" href="./static/favicon.ico" type="image/x-icon"/><link rel="icon" href="./static/favicon-256.jpg" sizes="256x256"/><link rel="preload" href="./static/fonts/open-sans-v28-latin-700.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v24-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v24-latin-italic.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/roboto-mono-v21-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="https://www.google-analytics.com/analytics.js" as="script"/><script src="https://www.googletagmanager.com/gtag/js?id=UA-114299226-1" async></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag("js", new Date());
  gtag("config", "UA-114299226-1", { "send_page_view": true });
</script><style>@font-face{font-display:swap;font-family:"Open Sans";font-style:normal;font-weight:700;src:local("Open Sans Bold"),local("OpenSans-Bold"),url(./static/fonts/open-sans-v28-latin-700.woff2) format("woff2"),url(./static/fonts/open-sans-v28-latin-700.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:normal;font-weight:400;src:local("Lora Regular"),local("Lora-Regular"),url(./static/fonts/lora-v24-latin-regular.woff2) format("woff2"),url(./static/fonts/lora-v24-latin-regular.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:italic;font-weight:400;src:local("Lora Italic"),local("Lora-Italic"),url(./static/fonts/lora-v24-latin-italic.woff2) format("woff2"),url(./static/fonts/lora-v24-latin-italic.woff) format("woff")}@font-face{font-display:swap;font-family:"Roboto Mono";font-style:normal;font-weight:400;src:local("Roboto Mono"),local("RobotoMono-Regular"),url(./static/fonts/roboto-mono-v21-latin-regular.woff2) format("woff2"),url(./static/fonts/roboto-mono-v21-latin-regular.woff) format("woff")}
/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:0.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace, monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}
html{box-sizing:border-box;overflow-y:scroll}*,*::before,*::after{box-sizing:inherit}body{font-family:"Lora", "Georgia", serif;font-weight:normal;background:#fff;color:#000;display:flex;flex-flow:row wrap;font-size:12pt;justify-content:space-between;line-height:1.5;margin:0 auto;width:90%}body>*{flex:100%}body>header{font-size:21pt;margin:10px 0}body>footer{border-top:3px solid gray;font-size:10pt;font-style:italic;padding:16px 0}header,nav,h1,h2{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}header a,nav a,h1 a,h2 a{color:inherit}a{color:blue;text-decoration:none}a:hover{color:blue;text-decoration:underline}strong{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}svg{fill:currentColor}.navmenu{border-top:3px solid gray;border-bottom:1px solid #ccc}.navmenu #toggle{float:right;height:24px;margin:4px 0;width:24px}.navmenu #toggle+label{color:transparent;cursor:pointer;display:block;padding:4px 0;position:relative;user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none}.navmenu #toggle+label::before{background:#fff;background-size:24px;content:"";float:right;height:24px;left:24px;position:relative;width:24px}.navmenu #toggle+label::after{content:"Menu";left:0;padding:0 16px;position:absolute}.navmenu #toggle+label{border-bottom:none}.navmenu #toggle+label::before{background-image:url("./static/chevron-down.svg")}.navmenu #toggle+label::after{color:#000}.navmenu #toggle~ul{height:0;visibility:hidden}.navmenu #toggle:checked+label{border-bottom:1px solid #e6e6e6}.navmenu #toggle:checked+label::before{background-image:url("./static/chevron-up.svg")}.navmenu #toggle:checked+label::after{color:gray}.navmenu #toggle:checked~ul{height:auto;visibility:visible}.navmenu ul{display:flex;flex-flow:column wrap;list-style-type:none;justify-content:flex-start;margin:0;overflow:hidden;padding:0}.navmenu ul>li{flex:none}.navmenu ul>li a{display:block;padding:4px 16px}.navmenu ul>li a:hover,.navmenu ul>li a:focus{background:gray;color:#fff}.content{max-width:720px}.content header,.content footer,.content h1,.content h2,.content p,.content ul,.content figure{margin:24px 0}.content h1{font-size:18pt}.content h2{font-size:12pt}.content footer{font-style:italic}.content p:last-of-type::after{clear:both;content:"";display:block}.content ul{padding-left:16px}.content ul>li{margin:12px 0}.content figure{max-width:90vw}.content figure>img{display:block}.content .fig-chart{padding-top:56.25%;page-break-inside:avoid;position:relative}.content .fig-chart>img{max-height:100%;max-width:100%;position:absolute;top:0}.content .fig-latex{overflow-x:auto}.content .fig-latex>img{margin:0 16px}.content .fig-pic-l>img,.content .fig-pic-r>img{margin:0 auto;max-width:100%;object-fit:cover}.content .button{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;background:#e6e6e6;color:inherit;display:block;margin:24px 0;padding:4px 0;text-align:center}.content .button:hover,.content .button:focus{background:gray;color:#fff}.content .message header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .message header>h1::first-letter{text-transform:uppercase}.content .message header>h1::after{content:":"}.content .message p{font-style:italic}.content .newpost header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .newpost header>h1::first-letter{text-transform:uppercase}.content .newpost header>h1::after{content:":"}.content .newpost header>h2{font-size:18pt}.content .newpost a.readmore::after{content:" \00bb"}.content .newpost a:not(.readmore):not(:hover){color:inherit}.content .oldpost{margin:24px 0}.content .oldpost header>h1{display:none}.content .archive ul>li time{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:none;font-size:10pt}.content .contact label,.content .contact input[type="submit"]{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;cursor:pointer;display:block;margin:16px 0}.content .contact label{margin-bottom:4px}.content .contact input[type="text"],.content .contact input[type="email"],.content .contact textarea{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;line-height:inherit;padding:4px;width:100%}.content .contact textarea{height:200px;max-width:100%;min-width:100%}.content .contact input[type="submit"]{padding:4px 40px}.content .comments{margin:24px 0 8px}.content .comments header>h2{display:none}.content .comments noscript{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;margin:-12px 0 24px}.sidebar header>h1{display:none}.sidebar header>h2{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0}.sidebar section{margin:24px 0}.sidebar section:first-of-type{margin-top:0}.sidebar .social-media ul{list-style:none;padding:0 0 0 16px}.sidebar .social-media ul>li a{display:inline-block}.sidebar .social-media ul>li a *{vertical-align:middle}.sidebar .social-media ul>li a span{margin:0 10px}.sidebar .social-media ul>li a svg{color:gray;height:48px;width:48px}.sidebar .social-media ul>li a:hover svg{color:inherit}.content p:not(.nojustify),.sidebar p:not(.nojustify){text-align:justify;word-spacing:-1px}.content p,.content ul,.sidebar p,.sidebar ul{line-height:1.667}@media only screen and (min-width: 600px){.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{max-width:720px}body>header{font-size:24pt}.navmenu #toggle{display:none}.navmenu #toggle+label{display:none}.navmenu #toggle~ul{height:auto;visibility:visible}.navmenu ul{flex-flow:row wrap}.navmenu ul>li a{padding:4px 32px}}@media only screen and (min-width: 1200px){body{column-gap:60px;max-width:1200px;min-width:1080px}body>header{text-align:center}.content{flex:auto;width:720px}.sidebar{flex:auto}.sidebar section:first-of-type{margin-top:40px}}@media only print{.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{display:block;margin:auto;width:125%}body>header{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0;text-align:left}.content figure{max-width:100%}.navmenu,.sidebar,.oldpost,.comments{display:none}}@page{margin:1in 1.25in}
</style></head><body><header><a href="./">Jim Killingsworth</a></header><nav class="navmenu"><input id="toggle" type="checkbox"/><label for="toggle">Enable menu</label><ul><li><a href="./"> Home </a></li><li><a href="./archive/"> Archive </a></li><li><a href="./about/"> About </a></li><li><a href="./contact/"> Contact </a></li></ul></nav><main class="content"><article><header><h1>Per­for­mance Tun­ing for the Coin Toss Mod­el</h1></header><p>I wrapped up the <a href="/2021/05/31/approximations-with-polynomials/">last post</a> ex­press­ing a de­sire to study the ap­prox­i­ma­tion tech­nique us­ing larg­er mod­els of the coin toss game. Up un­til now, I was us­ing a naive im­ple­men­ta­tion of the com­pu­ta­tion method to per­form the cal­cu­la­tion­s—an im­ple­men­ta­tion that was crude­ly im­ple­ment­ed and too slow for larg­er mod­el­s. In this post, I demon­strate an al­ter­na­tive ap­proach that has a much bet­ter per­for­mance pro­file. I al­so de­scribe a sim­ple tech­nique that can be used to re­duce the num­ber of it­er­a­tions re­quired when ap­ply­ing the hill climb­ing al­go­rith­m.</p><h2 id="optimized-computation-method">Op­ti­mized Com­pu­ta­tion Method</h2><p>To get around the per­for­mance is­sues ref­er­enced above, I de­cid­ed to im­ple­ment the com­pu­ta­tion method us­ing an en­tire­ly dif­fer­ent ap­proach. I think the best way to de­scribe this new ap­proach is to work through an ex­am­ple. Sup­pose we have a mod­el of the coin toss game with four coin toss events per round:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-01-latex-0078029047.svg" alt="Figure 1" height="14"></figure><p>Just like we did in some of the pre­vi­ous post­s, we can cre­ate a graph­i­cal rep­re­sen­ta­tion of the coin toss mod­el us­ing a state di­a­gram:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-02-latex-2441202334.svg" alt="Figure 2" height="384"></figure><p>This di­a­gram il­lus­trates the start­ing state and all of the pos­si­ble state tran­si­tion­s. In this case, we use one set of vari­ables to rep­re­sent state tran­si­tions away from the ini­tial state and an­oth­er set of vari­ables to rep­re­sent state tran­si­tions to­wards the ini­tial state. Here is the re­la­tion­ship be­tween these two sets of vari­ables:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-03-latex-1379633680.svg" alt="Figure 3" height="19"></figure><p>We want to pre­com­pute these val­ues ahead of time and look them up lat­er in­stead of com­put­ing them on the fly. Since our mod­el is sym­met­ri­cal by de­f­i­n­i­tion, we can as­sume the coin in the ini­tial state is al­ways a fair coin:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-04-latex-2013353180.svg" alt="Figure 4" height="18"></figure><p>For this ex­am­ple, let’s choose some ar­bi­trary val­ues for the re­main­ing state tran­si­tion­s:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-05-latex-2873578394.svg" alt="Figure 5" height="71"></figure><p>Now we want to cre­ate some lookup ta­bles for our state tran­si­tion val­ues. We’ll use these lookup ta­bles when com­put­ing the like­li­hood of land­ing on each one of the states af­ter each toss of the coin. Let’s cre­ate two ar­rays and pop­u­late them with these val­ues:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-06-latex-1999054460.svg" alt="Figure 6" height="235"></figure><p>These are our lookup ta­bles. No­tice that these ar­rays are padded with three ex­tra el­e­ments, one in the front and two in the back. You’ll see in a minute why this is nec­es­sary. We are us­ing point­ers to re­fer to the first val­ue in each ar­ray. Now let’s do some point­er arith­metic:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-07-latex-0837263748.svg" alt="Figure 7" height="62"></figure><p>One point­er is in­cre­ment­ed, while the oth­er is decre­ment­ed. This ef­fec­tive­ly shifts these ar­rays, one to the right and one to the left. We want to align them in a way that makes it easy to per­form our com­pu­ta­tions lat­er on. Here is how our lookup ta­bles ap­pear af­ter the shift:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-08-latex-3616774934.svg" alt="Figure 8" height="237"></figure><p>By de­f­i­n­i­tion, every round of the coin toss game starts out in the ze­ro state, so we know with 100% cer­tain­ty what state we’re go­ing to be in be­fore the first coin toss. Thus, we can rep­re­sent our ini­tial state vec­tor with the fol­low­ing ar­ray:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-09-latex-0228700456.svg" alt="Figure 9" height="125"></figure><p>This ar­ray is al­lo­cat­ed to the same size as the ar­rays used for the state tran­si­tion lookup ta­bles. And like be­fore, we use a point­er to re­fer to the first val­ue in the ar­ray. Now let’s do some more point­er arith­metic:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-10-latex-0074158466.svg" alt="Figure 10" height="65"></figure><p>In this case, we cre­ate a pair of point­ers that point to two dif­fer­ent el­e­ments of the same ar­ray. We can treat these two point­ers as if they were point­ers to two dif­fer­ent ar­rays, even though they’re re­al­ly not. In essence, this is what our two ar­rays look like:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-11-latex-0926642669.svg" alt="Figure 11" height="239"></figure><p>Now that we have ar­rays rep­re­sent­ing our state tran­si­tion val­ues and our ini­tial state vec­tor, along with point­ers that prop­er­ly align the data, we can com­pute the val­ues of the state vec­tor af­ter each toss of the coin. Here is the al­go­rith­m:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-12-latex-2953305660.svg" alt="Figure 12" height="155"></figure><p>No­tice that we al­ways dou­ble the val­ue in the ze­ro off­set at the end of each it­er­a­tion of the out­er loop. This is nec­es­sary be­cause we are on­ly solv­ing half the prob­lem. Since we know our mod­el is sym­met­ri­cal, we don’t both­er to cal­cu­late val­ues for tran­si­tions in­to the neg­a­tive states. They are al­ways a mir­ror im­age of the val­ues for the pos­i­tive states. How­ev­er, we do need to con­sid­er the neg­a­tive state that tran­si­tions in­to the ze­ro state. It is the same as the pos­i­tive state that tran­si­tions in­to the ze­ro state, hence the dou­bling.</p><p>Here are the com­put­ed val­ues af­ter out­er loop it­er­a­tion #1:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-13-latex-4023732679.svg" alt="Figure 13" height="349"></figure><p>Here are the com­put­ed val­ues af­ter out­er loop it­er­a­tion #2:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-14-latex-0725765104.svg" alt="Figure 14" height="349"></figure><p>Here are the com­put­ed val­ues af­ter out­er loop it­er­a­tion #3:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-15-latex-3323978084.svg" alt="Figure 15" height="349"></figure><p>Here are the com­put­ed val­ues af­ter out­er loop it­er­a­tion #4:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-16-latex-2140972058.svg" alt="Figure 16" height="349"></figure><p>Once the loop ter­mi­nates, we have the prob­a­bil­i­ties of land­ing on each state af­ter the fourth and fi­nal toss of the coin. States with a ze­ro val­ue are nev­er ter­mi­nal states. The states with non-ze­ro val­ues are the ter­mi­nal states. Here are the rel­e­vant val­ues:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-17-latex-1870717318.svg" alt="Figure 17" height="71"></figure><p>Is this the most op­ti­mal com­pu­ta­tion method? Prob­a­bly not. For even-num­bered coin toss­es, the odd­-num­bered states are al­ways ze­ro. For odd­-num­bered coin toss­es, the even-num­bered states are al­ways ze­ro. We could prob­a­bly use this knowl­edge to op­ti­mize the in­ner loop even fur­ther, but it might make the al­go­rithm a lit­tle more com­pli­cat­ed.</p><p>Con­sid­er al­so that each it­er­a­tion of the in­ner loop is in­de­pen­dent of the oth­er­s. This means that they can be run out of or­der or in par­al­lel. Since we’re us­ing point­ers to ref­er­ence el­e­ments of the state tran­si­tion lookup ta­bles and state vec­tor ar­rays, we could eas­i­ly mod­i­fy our pro­gram to use hard­ware-spe­cif­ic SIMD in­trin­sics such as those for the SSE or AVX in­struc­tion set­s. This would al­low us to par­al­lelize the com­pu­ta­tions in the in­ner loop.</p><h2 id="counting-the-floating-point-operations">Count­ing the Float­ing-Point Op­er­a­tions</h2><p>The ex­am­ple we worked through in the com­pu­ta­tion method de­scribed above is small enough that we can eas­i­ly count the num­ber of float­ing-point op­er­a­tions re­quired to com­pute the re­sult. Here is a ta­ble show­ing the count of all ad­di­tion and mul­ti­pli­ca­tion op­er­a­tions need­ed to com­plete each it­er­a­tion of the out­er loop:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-18-latex-0043747089.svg" alt="Figure 18" height="168"></figure><p>We can add up the to­tal num­ber of op­er­a­tions for each it­er­a­tion of the out­er loop to ar­rive at the to­tal num­ber of op­er­a­tions nec­es­sary to reach the fi­nal re­sult:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-19-latex-0620445755.svg" alt="Figure 19" height="18"></figure><p>This tells us how many op­er­a­tions are re­quired for a mod­el with four coin toss events. But what if we’re us­ing a much larg­er mod­el of the coin toss game? The fol­low­ing ta­ble shows how to com­pute the num­ber of op­er­a­tions re­quired for any it­er­a­tion of the out­er loop, re­gard­less of the size of the coin toss mod­el:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-20-latex-1010554507.svg" alt="Figure 20" height="69"></figure><p>Now we need to add up the num­ber of op­er­a­tions used in each it­er­a­tion to get the to­tal num­ber of op­er­a­tions re­quired to com­pute the fi­nal re­sult:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-21-latex-3406258622.svg" alt="Figure 21" height="50"></figure><p>This for­mu­la tells us the to­tal num­ber of float­ing-point op­er­a­tions nec­es­sary to cal­cu­late the fi­nal re­sult for a coin toss mod­el with an ar­bi­trary num­ber of coin toss events. But I think it might be con­ve­nient to rep­re­sent this in al­ge­bra­ic form in­stead of sum­ma­tion for­m. Con­sid­er the fol­low­ing re­la­tion­ship:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-22-latex-0455766630.svg" alt="Figure 22" height="50"></figure><p>This is the for­mu­la for the tri­an­gu­lar num­ber se­quence. We can use this re­la­tion­ship to re­place the sum­ma­tion above and present our so­lu­tion in the fol­low­ing al­ge­bra­ic for­m:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-23-latex-1380130384.svg" alt="Figure 23" height="41"></figure><p>As you can see, this in­di­cates that our al­go­rithm has qua­drat­ic time com­plex­i­ty. But this does­n’t tell us every­thing. How we ac­cess mem­o­ry and whether or not we make ef­fi­cient use of the cache can have an im­pact on per­for­mance re­gard­less of the num­ber of float­ing-point op­er­a­tions re­quired to com­plete a task.</p><h2 id="comparison-to-matrix-multiplication">Com­par­i­son to Ma­trix Mul­ti­pli­ca­tion</h2><p>In my ear­li­er post ti­tled <a href="/2021/02/25/generalizing-the-coin-toss-markov-model/"><em>Gen­er­al­iz­ing the Coin Toss Markov Mod­el</em></a>, we in­ves­ti­gat­ed a com­pu­ta­tion method based on the prod­uct of state vec­tors and state tran­si­tion ma­tri­ces. I am cu­ri­ous how this com­pu­ta­tion method com­pares to the op­ti­mized com­pu­ta­tion method an­a­lyzed in the pre­vi­ous sec­tion. For this analy­sis, we’ll use the fol­low­ing no­ta­tion:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-24-latex-0116377550.svg" alt="Figure 24" height="90"></figure><p>We can think of the row vec­tor as a ma­trix with a sin­gle row. Let’s start by first count­ing the num­ber of op­er­a­tions need­ed to com­pute the prod­uct of two square ma­tri­ces and the num­ber of op­er­a­tions need­ed to com­pute the prod­uct of a row vec­tor and a square ma­trix:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-25-latex-3828499854.svg" alt="Figure 25" height="135"></figure><p>The num­ber of op­er­a­tions re­quired de­pends on the size of the ma­trix. And the size of the ma­trix de­pends on the num­ber of coin toss events we are mod­el­ing. But the num­ber of ma­trix op­er­a­tions we need to com­pute al­so de­pends on the num­ber of coin toss events. Re­call the fol­low­ing for­mu­la from our gen­er­al­ized coin toss Markov mod­el:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-26-latex-2967125593.svg" alt="Figure 26" height="19"></figure><p>If we are mod­el­ing a sys­tem with four coin toss events, we can ex­pand the above as fol­lows:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-27-latex-2444608179.svg" alt="Figure 27" height="18"></figure><p>In this case, there are a to­tal of four ma­trix op­er­a­tions. Each ma­trix op­er­a­tion con­tains many el­e­men­tary op­er­a­tions. We want to count the num­ber of el­e­men­tary op­er­a­tions. Since ma­trix mul­ti­pli­ca­tion is as­so­cia­tive, we’ll get the same re­sult whether we eval­u­ate the ex­pres­sion from left to right or right to left­—as­sum­ing we don’t have any float­ing-point round­ing er­rors. But the num­ber of el­e­men­tary op­er­a­tions re­quired to eval­u­ate this ex­pres­sion de­pends on the or­der in which we per­form the eval­u­a­tion. Here is the analy­sis for right-as­so­cia­tive eval­u­a­tion:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-28-latex-0387339572.svg" alt="Figure 28" height="135"></figure><p>Us­ing this in­for­ma­tion, we can ex­press the to­tal num­ber of float­ing-point op­er­a­tions as a func­tion of the num­ber of coin toss events:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-29-latex-4289137432.svg" alt="Figure 29" height="110"></figure><p>Thus, our ma­trix prod­uct has a quar­tic poly­no­mi­al time com­plex­i­ty when us­ing right-as­so­cia­tive eval­u­a­tion. We can use this for­mu­la to com­pute the to­tal num­ber of el­e­men­tary op­er­a­tions need­ed for a mod­el with four coin toss events:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-30-latex-0130141746.svg" alt="Figure 30" height="18"></figure><p>This is about two or­ders of mag­ni­tude more than the num­ber of op­er­a­tions re­quired when us­ing the op­ti­mized com­pu­ta­tion method. And the gap is even worse for mod­els with a high­er num­ber of coin toss events. But the dif­fer­ence is not as bad if we eval­u­ate the ma­trix prod­uct from left to right in­stead of right to left. Here is the analy­sis for left­-as­so­cia­tive eval­u­a­tion:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-31-latex-4177985283.svg" alt="Figure 31" height="135"></figure><p>Us­ing this in­for­ma­tion, we can ex­press the to­tal num­ber of float­ing-point op­er­a­tions as a func­tion of the num­ber of coin toss events:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-32-latex-2630528705.svg" alt="Figure 32" height="109"></figure><p>Ac­cord­ing­ly, our ma­trix prod­uct has cu­bic poly­no­mi­al time com­plex­i­ty when us­ing left­-as­so­cia­tive eval­u­a­tion. We can use this for­mu­la to com­pute the to­tal num­ber of el­e­men­tary op­er­a­tions need­ed for a mod­el with four coin toss events:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-33-latex-1583057697.svg" alt="Figure 33" height="18"></figure><p>This is a bet­ter fig­ure, but it’s still more than ten times the num­ber of op­er­a­tions re­quired when us­ing the op­ti­mized com­pu­ta­tion method. And the gap still gets worse for mod­els with a high­er num­ber of coin toss events. For each com­pu­ta­tion method, we can plot the num­ber of op­er­a­tions re­quired as a func­tion of the num­ber of coin toss events to get an idea of what the growth rate of each method looks like:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-34-flop-counts.svg" alt="Figure 34" height="405" width="720"></figure><p>Keep in mind that the ver­ti­cal ax­is has a log­a­rith­mic scale. As you can see, the op­ti­mized com­pu­ta­tion method scales much bet­ter than meth­ods us­ing ma­trix mul­ti­pli­ca­tion. And per­haps this is not sur­pris­ing when you con­sid­er that, in the gen­er­al­ized coin toss mod­el, the state tran­si­tion ma­trix is a sparse ma­trix that con­tains most­ly ze­ros. Per­form­ing ad­di­tion and mul­ti­pli­ca­tion op­er­a­tions against those ze­ro val­ues is a waste of com­pu­ta­tion re­sources.</p><h2 id="comparison-to-algebraic-manipulation">Com­par­i­son to Al­ge­bra­ic Ma­nip­u­la­tion</h2><p>Sup­pose we have a set of al­ge­bra­ic for­mu­las that we can use to com­pute the ex­pect­ed out­come of the coin toss game giv­en a set of bi­as­es. We might be able to cal­cu­late the re­sults with few­er op­er­a­tions than any of the meth­ods de­scribed above. In an ear­li­er post ti­tled <a href="/2019/09/14/estimating-the-weights-of-biased-coins/"><em>Es­ti­mat­ing the Weights of Bi­ased Coins</em></a>, we de­rived a set of equa­tions to com­pute the out­come for a mod­el of the coin toss game with four coin toss events. Let’s do some­thing sim­i­lar here:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-35-latex-0837013881.svg" alt="Figure 35" height="563"></figure><p>With four coin toss events, there are six­teen pos­si­ble coin toss se­quences. The ta­ble above shows the prob­a­bil­i­ty of each one, along with the ter­mi­nal state af­ter the fi­nal coin toss. We can ex­press the chance of end­ing up in each one of the fi­nal states with the fol­low­ing:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-36-latex-1498287436.svg" alt="Figure 36" height="115"></figure><p>Re­mem­ber, the coin in the ini­tial state is al­ways a fair coin. The for­mu­las above can be sim­pli­fied to con­tain few­er op­er­a­tions:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-37-latex-3462926879.svg" alt="Figure 37" height="115"></figure><p>You might want to stop here and check my work to make sure I did this cor­rect­ly. It’s easy to make a mis­take. With these for­mu­las, we can now count all the ad­di­tion and mul­ti­pli­ca­tion op­er­a­tions to get the to­tal num­ber of float­ing-point op­er­a­tions need­ed to com­pute the re­sult­s:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-38-latex-1014429691.svg" alt="Figure 38" height="135"></figure><p>Adding up the to­tal num­ber of op­er­a­tions for each re­sult, we find that, at least in the case where there are four coin toss events, there are few­er op­er­a­tions re­quired than with any of the com­pu­ta­tion meth­ods ex­am­ined in the pre­vi­ous sec­tion­s:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-39-latex-3956110410.svg" alt="Figure 39" height="18"></figure><p>It’s not clear to me how to gen­er­al­ize this for a mod­el with an ar­bi­trary num­ber of coin toss events. How­ev­er, it is clear to me that the prob­a­bil­i­ty of get­ting a se­quence of all heads or all tail­s, re­gard­less of the num­ber of coin toss­es, can be ex­pressed like this:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-40-latex-0785116985.svg" alt="Figure 40" height="52"></figure><p>This com­pu­ta­tion has lin­ear time com­plex­i­ty. The num­ber of op­er­a­tions re­quired is di­rect­ly pro­por­tion­al to the num­ber of coin toss events. Know­ing this, we can as­sume that an ap­proach us­ing pre­de­ter­mined al­ge­bra­ic for­mu­las has at least a lin­ear growth rate. That’s a best-case sce­nar­i­o. But re­al­is­ti­cal­ly, it’s prob­a­bly not that good. Nonethe­less, this ap­proach still might have a bet­ter per­for­mance pro­file than the op­ti­mized com­pu­ta­tion method we de­tailed ear­lier. It might be worth ex­plor­ing this idea fur­ther.</p><h2 id="performance-bottleneck">Per­for­mance Bot­tle­neck</h2><p>The chal­lenge with us­ing the al­ge­bra­ic ap­proach is com­ing up with the for­mu­las for mod­els with a high num­ber of coin toss events. These for­mu­las al­so need to be eval­u­at­ed in a man­ner that has an ac­cept­able per­for­mance pro­file. In some of the pre­vi­ous post­s, I used a <a href="https://symbolics.mathdotnet.com/">com­put­er al­ge­bra li­brary</a> to build up ex­pres­sion trees rep­re­sent­ing the al­ge­bra­ic for­mu­las. These ex­pres­sion trees were then mapped to a <a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/expression-trees/">dif­fer­ent ex­pres­sion tree for­mat</a> and com­piled in­to ex­e­cutable func­tion­s.</p><p>This method worked beau­ti­ful­ly for small­er mod­els of the coin toss game. But the com­pi­la­tion step turned out to be one of the per­for­mance bot­tle­necks pre­vent­ing this method from be­ing used for larg­er mod­els of the coin toss game. Fur­ther­more, the ex­e­cutable func­tions gen­er­at­ed by the com­pi­la­tion step did­n’t run near­ly as fast as the op­ti­mized com­pu­ta­tion method. I was al­so run­ning in­to stack over­flow er­rors when at­tempt­ing to solve for larg­er mod­el­s. It was un­us­able for mod­els with more than about twen­ty coin toss events. I haven’t looked too deeply in­to it yet, but I think I might know what the prob­lem is. Con­sid­er the fol­low­ing ex­pres­sion:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-41-latex-2171351888.svg" alt="Figure 41" height="15"></figure><p>This is just a sum of four num­ber­s. For this for­mu­la, the ex­pres­sion tree gen­er­at­ed by the com­put­er al­ge­bra li­brary would look like this:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-42-latex-4028407798.svg" alt="Figure 42" height="131"></figure><p>This re­mains a very flat tree struc­ture re­gard­less of how many num­bers we are adding to­geth­er. Ide­al­ly, the sum would be com­piled as a loop with an ac­cu­mu­la­tor. But that’s not what hap­pen­s. In prepa­ra­tion for the com­pi­la­tion step, this ex­pres­sion tree gets mapped to a bi­na­ry ex­pres­sion tree for­mat that looks like this:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-43-latex-1218695308.svg" alt="Figure 43" height="227"></figure><p>For com­plex ex­pres­sions with many operand­s, this can be a very deeply nest­ed tree struc­ture. And that’s where I think the prob­lem lies. This deep tree struc­ture might be what was caus­ing the com­pi­la­tion step to take a long time. It might al­so ex­plain why the gen­er­at­ed func­tions ran too slow­ly and why the eval­u­a­tion of larg­er mod­els was ex­haust­ing the call stack.</p><h2 id="hill-climbing-with-descending-step-sizes">Hill Climb­ing with De­scend­ing Step Sizes</h2><p>In some of the ex­am­ples we looked at in the pre­vi­ous post­s, we used a hill climb­ing al­go­rithm as an op­ti­miza­tion tech­nique to find pa­ra­me­ters that min­i­mize a cost func­tion. In all of these ex­am­ples, we used a fixed step size. In the last post, we used a step size that would de­liv­er an ac­cu­ra­cy of five dec­i­mal places:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-44-latex-3654662009.svg" alt="Figure 44" height="20"></figure><p>Con­sid­er the ex­am­ples il­lus­trat­ed for the <a href="/2021/05/31/approximations-with-polynomials/#linear-polynomial">lin­ear poly­no­mi­al method</a> in the pre­vi­ous post. Ap­ply­ing the hill climb­ing al­go­rithm while us­ing this val­ue as the step size, the op­ti­miza­tion task took tens of thou­sands of it­er­a­tions to com­plete. We can sig­nif­i­cant­ly re­duce the num­ber of it­er­a­tions nec­es­sary by us­ing a se­ries of tiered step sizes arranged in de­scend­ing or­der:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-45-latex-1470015507.svg" alt="Figure 45" height="124"></figure><p>The ob­jec­tive here is to run the hill climb­ing al­go­rithm to com­ple­tion us­ing the first step size. Once com­plete, the process is re­peat­ed with the next step size us­ing the re­sult of the pre­vi­ous run as the start­ing point. We keep re­peat­ing this process un­til we’ve run the al­go­rithm to com­ple­tion for the small­est step size. Re­pro­duc­ing the lin­ear poly­no­mi­al ex­am­ples from the pre­vi­ous post, here are the paths tak­en by the hill climb­ing al­go­rithm when us­ing de­scend­ing step sizes:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-46-estimate-n-10-1-heatmap.svg" alt="Figure 46" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-47-estimate-n-10-2-heatmap.svg" alt="Figure 47" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-48-estimate-n-10-3-heatmap.svg" alt="Figure 48" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-49-estimate-n-10-4-heatmap.svg" alt="Figure 49" height="405" width="720"></figure><p>Ex­cept for the last one, which drifts off in­to a lo­cal min­i­mum, all paths fin­ish with the same re­sult. And this re­sult is the same one we found when us­ing a fixed step size. But when us­ing de­scend­ing step sizes, the re­sults con­verge in far few­er it­er­a­tions. Here is a com­par­ison:</p><figure class="fig-latex"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-50-latex-0836126839.svg" alt="Figure 50" height="168"></figure><p>The dif­fer­ence is off the chart­s. Be­gin­ning the hill climb­ing method with a large step size al­lows the process to move quick­ly to­wards the tar­get area, while the small­er step sizes en­able it to ze­ro in on a pre­cise re­sult. The ben­e­fits are clear. And this tech­nique might be use­ful for oth­er op­ti­miza­tion meth­ods as well.</p><h2 id="example-with-20-coin-tosses">Ex­am­ple with 20 Coin Toss­es</h2><p>With the per­for­mance en­hance­ments out­lined in the sec­tions above, we can now ap­ply the poly­no­mi­al ap­prox­i­ma­tion tech­nique to larg­er mod­els of the coin toss game. Us­ing a mod­el of the coin toss game with twen­ty coin toss events, let’s use the <a href="/2021/05/31/approximations-with-polynomials/#quadratic-polynomial">qua­drat­ic poly­no­mi­al ap­prox­i­ma­tion</a> tech­nique de­scribed in the pre­vi­ous post to find a set of weights that ap­prox­i­mate the fol­low­ing tar­get dis­tri­b­u­tion:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-51-target-pmfunc-n-20.svg" alt="Figure 51" height="405" width="720"></figure><p>Start­ing with a set of fair coins for the ini­tial guess, we can ap­ply the hill climb­ing al­go­rithm to find an op­ti­mal set of weights for the bi­ased coin­s. The process com­pletes af­ter 25 it­er­a­tions. Here are the re­sult­s:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-52-estimate-n-20-5-biases-fitted.svg" alt="Figure 52" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-53-estimate-n-20-5-pmfunc-fitted.svg" alt="Figure 53" height="405" width="720"></figure><p>The re­sults are com­put­ed al­most in­stan­ta­neous­ly. With­out the op­ti­mized com­pu­ta­tion method, these cal­cu­la­tions would have tak­en about twen­ty sec­onds to run on my cur­rent hard­ware. And with­out the de­scend­ing step size op­ti­miza­tion, this task would have tak­en about thir­ty minutes to com­plete.</p><h2 id="example-with-50-coin-tosses">Ex­am­ple with 50 Coin Toss­es</h2><p>Let’s do an­oth­er ex­am­ple. In this one, we’ll use the <a href="/2021/05/31/approximations-with-polynomials/#cubic-polynomial">cu­bic poly­no­mi­al ap­prox­i­ma­tion</a> tech­nique on a mod­el with fifty coin toss events. A mod­el this size would be im­prac­ti­cal or im­pos­si­ble to eval­u­ate with­out the per­for­mance op­ti­miza­tions chron­i­cled in this post. Here is the tar­get dis­tri­b­u­tion we want to ap­prox­i­mate:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-54-target-pmfunc-n-50.svg" alt="Figure 54" height="405" width="720"></figure><p>Start­ing with a set of fair coins for the ini­tial guess, we can ap­ply the hill climb­ing al­go­rithm to find an op­ti­mal set of weights for the bi­ased coin­s. The process com­pletes af­ter 1,746 it­er­a­tions. Here are the re­sult­s:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-55-estimate-n-50-6-biases-fitted.svg" alt="Figure 55" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2021/07/12/performance-tuning-for-the-coin-toss-model/fig-56-estimate-n-50-6-pmfunc-fitted.svg" alt="Figure 56" height="405" width="720"></figure><p>This is a pret­ty good ap­prox­i­ma­tion, but it is not the most op­ti­mal re­sult that can be found with a cu­bic poly­no­mi­al. When us­ing fair coins for the ini­tial guess, the hill climb­ing method takes a route that ap­pears to lead to a lo­cal min­i­mum. Al­so, no­tice that the num­ber of it­er­a­tions re­quired is two or­ders of mag­ni­tude more than the oth­er ex­am­ples in the last two sec­tion­s. I have some ideas for im­prov­ing this tech­nique fur­ther, but I will save that dis­cus­sion for an­oth­er time.</p><p class="nojustify"><a href="https://github.com/jkillingsworth/jkillingsworth.com/tree/master/src/2021-07-12-performance-tuning-for-the-coin-toss-model">Ac­com­pa­ny­ing source code is avail­able on GitHub.</a></p><footer><time datetime="2021-07-12">July 12, 2021</time></footer></article><section class="comments"><header><h2>Com­ments</h2></header><script>
    var disqus_config = function () {
      this.page.url = "https://jkillingsworth.com/2021/07/12/performance-tuning-for-the-coin-toss-model/";
      this.page.title = "Performance Tuning for the Coin Toss Model";
      this.page.identifier = "/2021/07/12/performance-tuning-for-the-coin-toss-model/";
    };
    function disqus_show() {
      var d = document, s = d.createElement("script");
      s.src = "https://jkillingsworth.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    }
    function anchor_blur() {
      var a = document.getElementById("comments");
      a.innerText = "Comments";
      a.blur();
    }
    function disqus() {
      disqus_show();
      anchor_blur();
    }
  </script><a href="javascript:disqus();" id="comments" class="button">Show comments</a><div id="disqus_thread"></div><noscript> Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></section></main><aside class="sidebar"><header><h1>Sidebar</h1></header><section class="social-media"><header><h2>Social Media</h2></header><ul><li><a href="https://www.linkedin.com/in/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M417.2 64H96.8C79.3 64 64 76.6 64 93.9V415c0 17.4 15.3 32.9 32.8 32.9h320.3c17.6 0 30.8-15.6 30.8-32.9V93.9C448 76.6 434.7 64 417.2 64zM183 384h-55V213h55v171zm-25.6-197h-.4c-17.6 0-29-13.1-29-29.5 0-16.7 11.7-29.5 29.7-29.5s29 12.7 29.4 29.5c0 16.4-11.4 29.5-29.7 29.5zM384 384h-55v-93.5c0-22.4-8-37.7-27.9-37.7-15.2 0-24.2 10.3-28.2 20.3-1.5 3.6-1.9 8.5-1.9 13.5V384h-55V213h55v23.8c8-11.4 20.5-27.8 49.6-27.8 36.1 0 63.4 23.8 63.4 75.1V384z"/></svg><span>LinkedIn</span></a></li><li><a href="https://github.com/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9 1.4.3 2.6.4 3.8.4 8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1-8.4 1.9-15.9 2.7-22.6 2.7-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1 10.5 0 20-3.4 25.6-6 2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8 0 0 1.6-.5 5-.5 8.1 0 26.4 3.1 56.6 24.1 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 30.2-21 48.5-24.1 56.6-24.1 3.4 0 5 .5 5 .5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5 1.2 0 2.6-.1 4-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z"/></svg><span>GitHub</span></a></li></ul></section></aside><footer> &copy; 2018&ndash;2022 Jim Killingsworth. All rights reserved. </footer></body></html>