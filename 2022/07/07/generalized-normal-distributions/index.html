<!doctype html><html lang="en-US"><head><title>Generalized Normal Distributions - Jim Killingsworth</title><meta charset="utf-8"/><meta name="referrer" content="no-referrer-when-downgrade"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="description" content="The generalized normal distribution is a family of probability distributions that vary according to a shape parameter. The symmetrical variant of this distribution may go by other names such as the generalized error distribution, the generalized Gaussian distribution, etc. In this post, we will explore this probability distribution and its relationship with the normal distribution and the Laplace distribution. I’ll also show some examples illustrating the use of the maximum likelihood method to estimate the parameters of the distribution using real-life data."/><base href="/"/><link rel="canonical" href="https://jkillingsworth.com/2022/07/07/generalized-normal-distributions/"/><link rel="icon" href="./static/favicon.ico" type="image/x-icon"/><link rel="icon" href="./static/favicon-256.jpg" sizes="256x256"/><link rel="preload" href="./static/fonts/open-sans-v29-latin-700.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v24-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v24-latin-italic.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/roboto-mono-v21-latin-regular.woff2" as="font" crossorigin/><script src="https://www.googletagmanager.com/gtag/js?id=G-KP25LH29N8" async></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag("js", new Date());
  gtag("config", "G-KP25LH29N8");
</script><style>@font-face{font-display:swap;font-family:"Open Sans";font-style:normal;font-weight:700;src:local("Open Sans Bold"),local("OpenSans-Bold"),url(./static/fonts/open-sans-v29-latin-700.woff2) format("woff2"),url(./static/fonts/open-sans-v29-latin-700.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:normal;font-weight:400;src:local("Lora Regular"),local("Lora-Regular"),url(./static/fonts/lora-v24-latin-regular.woff2) format("woff2"),url(./static/fonts/lora-v24-latin-regular.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:italic;font-weight:400;src:local("Lora Italic"),local("Lora-Italic"),url(./static/fonts/lora-v24-latin-italic.woff2) format("woff2"),url(./static/fonts/lora-v24-latin-italic.woff) format("woff")}@font-face{font-display:swap;font-family:"Roboto Mono";font-style:normal;font-weight:400;src:local("Roboto Mono"),local("RobotoMono-Regular"),url(./static/fonts/roboto-mono-v21-latin-regular.woff2) format("woff2"),url(./static/fonts/roboto-mono-v21-latin-regular.woff) format("woff")}
/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:0.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace, monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}
html{box-sizing:border-box;overflow-y:scroll}*,*::before,*::after{box-sizing:inherit}body{font-family:"Lora", "Georgia", serif;font-weight:normal;background:#fff;color:#000;display:flex;flex-flow:row wrap;font-size:12pt;justify-content:space-between;line-height:1.5;margin:0 auto;width:90%}body>*{flex:100%}body>header{font-size:21pt;margin:10px 0}body>footer{border-top:3px solid gray;font-size:10pt;font-style:italic;padding:16px 0}header,nav,h1,h2{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}header a,nav a,h1 a,h2 a{color:inherit}a{color:#0050ff;text-decoration:none}a:hover{color:#0050ff;text-decoration:underline}strong{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}svg{fill:currentColor}.navmenu{border-top:3px solid gray;border-bottom:1px solid #ccc}.navmenu #toggle{float:right;height:24px;margin:4px 0;width:24px}.navmenu #toggle+label{color:transparent;cursor:pointer;display:block;padding:4px 0;position:relative;user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none}.navmenu #toggle+label::before{background:#fff;background-size:24px;content:"";float:right;height:24px;left:24px;position:relative;width:24px}.navmenu #toggle+label::after{content:"Menu";left:0;padding:0 16px;position:absolute}.navmenu #toggle+label{border-bottom:none}.navmenu #toggle+label::before{background-image:url("./static/chevron-down.svg")}.navmenu #toggle+label::after{color:#000}.navmenu #toggle~ul{height:0;visibility:hidden}.navmenu #toggle:checked+label{border-bottom:1px solid #e6e6e6}.navmenu #toggle:checked+label::before{background-image:url("./static/chevron-up.svg")}.navmenu #toggle:checked+label::after{color:gray}.navmenu #toggle:checked~ul{height:auto;visibility:visible}.navmenu ul{display:flex;flex-flow:column wrap;list-style-type:none;justify-content:flex-start;margin:0;overflow:hidden;padding:0}.navmenu ul>li{flex:none}.navmenu ul>li a{display:block;padding:4px 16px}.navmenu ul>li a:hover,.navmenu ul>li a:focus{background:gray;color:#fff}.content{max-width:720px}.content header,.content footer,.content h1,.content h2,.content p,.content ul,.content figure{margin:24px 0}.content h1{font-size:18pt}.content h2{font-size:12pt}.content footer{font-style:italic}.content p:last-of-type::after{clear:both;content:"";display:block}.content ul{padding-left:16px}.content ul>li{margin:12px 0}.content figure{max-width:90vw}.content figure>img{display:block}.content .fig-chart{padding-top:56.25%;page-break-inside:avoid;position:relative}.content .fig-chart>img{max-height:100%;max-width:100%;position:absolute;top:0}.content .fig-latex{overflow-x:auto}.content .fig-latex>img{margin:0 16px}.content .fig-pic-l>img,.content .fig-pic-r>img{margin:0 auto;max-width:100%;object-fit:cover}.content .button{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;background:#e6e6e6;color:inherit;display:block;margin:24px 0;padding:4px 0;text-align:center}.content .button:hover,.content .button:focus{background:gray;color:#fff}.content .message header>h1{background:#ffff60;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .message header>h1::first-letter{text-transform:uppercase}.content .message header>h1::after{content:":"}.content .message p{font-style:italic}.content .newpost header>h1{background:#ffff60;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .newpost header>h1::first-letter{text-transform:uppercase}.content .newpost header>h1::after{content:":"}.content .newpost header>h2{font-size:18pt}.content .newpost a.readmore{background:#e8f0ff}.content .newpost a.readmore::after{content:" \00bb"}.content .newpost a:not(.readmore):not(:hover){color:inherit}.content .oldpost{margin:24px 0}.content .oldpost header>h1{display:none}.content .archive ul>li time{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:none;font-size:10pt}.content .contact label,.content .contact input[type="submit"]{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;cursor:pointer;display:block;margin:16px 0}.content .contact label{margin-bottom:4px}.content .contact input[type="text"],.content .contact input[type="email"],.content .contact textarea{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;line-height:inherit;padding:4px;width:100%}.content .contact textarea{height:200px;max-width:100%;min-width:100%}.content .contact input[type="submit"]{padding:4px 40px}.content .comments{margin:24px 0 8px}.content .comments header>h2{display:none}.content .comments noscript{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;margin:-12px 0 24px}.sidebar header>h1{display:none}.sidebar header>h2{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0}.sidebar section{margin:24px 0}.sidebar section:first-of-type{margin-top:0}.sidebar .social-media ul{list-style:none;padding:0 0 0 16px}.sidebar .social-media ul>li a{display:inline-block}.sidebar .social-media ul>li a *{vertical-align:middle}.sidebar .social-media ul>li a span{margin:0 10px}.sidebar .social-media ul>li a svg{color:gray;height:48px;width:48px}.sidebar .social-media ul>li a:hover svg{color:inherit}.content p:not(.nojustify),.sidebar p:not(.nojustify){text-align:justify;word-spacing:-1px}.content p,.content ul,.sidebar p,.sidebar ul{line-height:1.667}@media only screen and (min-width: 600px){.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{max-width:720px}body>header{font-size:24pt}.navmenu #toggle{display:none}.navmenu #toggle+label{display:none}.navmenu #toggle~ul{height:auto;visibility:visible}.navmenu ul{flex-flow:row wrap}.navmenu ul>li a{padding:4px 32px}}@media only screen and (min-width: 1200px){body{column-gap:60px;max-width:1200px;min-width:1080px}body>header{text-align:center}.content{flex:auto;width:720px}.sidebar{flex:auto}.sidebar section:first-of-type{margin-top:40px}}@media only print{.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{display:block;margin:auto;width:125%}body>header{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0;text-align:left}.content figure{max-width:100%}.navmenu,.sidebar,.oldpost,.comments{display:none}}@page{margin:1in 1.25in}
</style></head><body><header><a href="./">Jim Killingsworth</a></header><nav class="navmenu"><input id="toggle" type="checkbox"/><label for="toggle">Enable menu</label><ul><li><a href="./"> Home </a></li><li><a href="./archive/"> Archive </a></li><li><a href="./about/"> About </a></li><li><a href="./contact/"> Contact </a></li></ul></nav><main class="content"><article><header><h1>Gen­er­al­ized Nor­mal Dis­tri­b­u­tions</h1></header><p>The gen­er­al­ized nor­mal dis­tri­b­u­tion is a fam­i­ly of prob­a­bil­i­ty dis­tri­b­u­tions that vary ac­cord­ing to a shape pa­ra­me­ter. The sym­met­ri­cal vari­ant of this dis­tri­b­u­tion may go by oth­er names such as the gen­er­al­ized er­ror dis­tri­b­u­tion, the gen­er­al­ized Gaussian dis­tri­b­u­tion, etc. In this post, we will ex­plore this prob­a­bil­i­ty dis­tri­b­u­tion and its re­la­tion­ship with the nor­mal dis­tri­b­u­tion and the Laplace dis­tri­b­u­tion. I’ll al­so show some ex­am­ples il­lus­trat­ing the use of the max­i­mum like­li­hood method to es­ti­mate the pa­ra­me­ters of the dis­tri­b­u­tion us­ing re­al-life data.</p><h2 id="probability-density-function">Prob­a­bil­i­ty Den­si­ty Func­tion</h2><p>The gen­er­al­ized nor­mal dis­tri­b­u­tion is a con­tin­u­ous prob­a­bil­i­ty dis­tri­b­u­tion with three pa­ra­me­ter­s: a lo­ca­tion pa­ra­me­ter, a scale pa­ra­me­ter, and a shape pa­ra­me­ter. The prob­a­bil­i­ty den­si­ty func­tion takes the fol­low­ing for­m:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-01-latex-3552660201.svg" alt="Figure 1" height="146"></figure><p>The lo­ca­tion pa­ra­me­ter can be neg­a­tive or pos­i­tive. The scale pa­ra­me­ter and the shape pa­ra­me­ter are al­ways pos­i­tive re­al num­ber­s. Note the use of the <a href="https://en.wikipedia.org/wiki/Gamma_function">gam­ma func­tion</a> above. The gam­ma func­tion looks like this:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-02-latex-2516353903.svg" alt="Figure 2" height="50"></figure><p>For prac­ti­cal pur­pos­es, we can just use a nu­mer­i­cal method to ap­prox­i­mate the gam­ma func­tion. I am us­ing a third-par­ty im­ple­men­ta­tion of the <a href="https://en.wikipedia.org/wiki/Lanczos_approximation">Lanc­zos ap­prox­i­ma­tion</a> for the il­lus­tra­tions in this post. If we hold the lo­ca­tion and scale pa­ra­me­ters con­stant and then vary the shape pa­ra­me­ter, we can see what the shape of the den­si­ty func­tion looks like for dif­fer­ent val­ues of the shape pa­ra­me­ter. Here are some il­lus­tra­tions:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-03-shape-0.50.svg" alt="Figure 3" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-04-shape-0.75.svg" alt="Figure 4" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-05-shape-1.00.svg" alt="Figure 5" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-06-shape-1.50.svg" alt="Figure 6" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-07-shape-2.00.svg" alt="Figure 7" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-08-shape-4.00.svg" alt="Figure 8" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-09-shape-8.00.svg" alt="Figure 9" height="405" width="720"></figure><p>If you think the den­si­ty func­tion looks like that of a Laplace dis­tri­b­u­tion when the shape pa­ra­me­ter is equal to one, then you would be cor­rec­t. And if you think the den­si­ty func­tion looks like that of a nor­mal dis­tri­b­u­tion when the shape pa­ra­me­ter is equal to two, then you would be cor­rect again. In­deed, both the nor­mal dis­tri­b­u­tion and the Laplace dis­tri­b­u­tion are spe­cial cas­es of the gen­er­al­ized nor­mal dis­tri­b­u­tion. The gen­er­al­ized nor­mal dis­tri­b­u­tion can al­so take the form of a uni­form dis­tri­b­u­tion as the shape pa­ra­me­ter ap­proach­es in­fin­i­ty.</p><h2 id="normal-distribution">Nor­mal Dis­tri­b­u­tion</h2><p>The nor­mal dis­tri­b­u­tion is a spe­cial case of the gen­er­al­ized nor­mal dis­tri­b­u­tion when the shape pa­ra­me­ter is equal to two. Con­sid­er the fol­low­ing:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-10-latex-2694150631.svg" alt="Figure 10" height="20"></figure><p>Plug these val­ues in­to the den­si­ty func­tion and re­place the scale pa­ra­me­ter with the fol­low­ing:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-11-latex-1270297145.svg" alt="Figure 11" height="18"></figure><p>We now have a fa­mil­iar rep­re­sen­ta­tion of the nor­mal dis­tri­b­u­tion:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-12-latex-2673146651.svg" alt="Figure 12" height="47"></figure><p>As you can see, by hold­ing the shape pa­ra­me­ter to a fixed val­ue of two, the gen­er­al­ized nor­mal dis­tri­b­u­tion can be treat­ed like a reg­u­lar nor­mal dis­tri­b­u­tion.</p><h2 id="laplace-distribution">Laplace Dis­tri­b­u­tion</h2><p>The Laplace dis­tri­b­u­tion is a spe­cial case of the gen­er­al­ized nor­mal dis­tri­b­u­tion when the shape pa­ra­me­ter is equal to one. Con­sid­er the fol­low­ing:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-13-latex-2501921651.svg" alt="Figure 13" height="19"></figure><p>Plug these val­ues in­to the den­si­ty func­tion and re­place the scale pa­ra­me­ter with the fol­low­ing:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-14-latex-0880579792.svg" alt="Figure 14" height="15"></figure><p>We now have a fa­mil­iar rep­re­sen­ta­tion of the Laplace dis­tri­b­u­tion:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-15-latex-0310385774.svg" alt="Figure 15" height="42"></figure><p>As you can see, by hold­ing the shape pa­ra­me­ter to a fixed val­ue of one, the gen­er­al­ized nor­mal dis­tri­b­u­tion can be treat­ed like a Laplace dis­tri­b­u­tion.</p><h2 id="numerical-parameter-estimation">Nu­mer­i­cal Pa­ra­me­ter Es­ti­ma­tion</h2><p>If you have a set of ob­served da­ta that is dis­trib­uted ac­cord­ing to a known prob­a­bil­i­ty dis­tri­b­u­tion, you can use the max­i­mum like­li­hood method to es­ti­mate the pa­ra­me­ters of the dis­tri­b­u­tion. If the dis­tri­b­u­tion is a nor­mal dis­tri­b­u­tion or a Laplace dis­tri­b­u­tion, the pa­ra­me­ter val­ues can be solved for an­a­lyt­i­cal­ly by tak­ing the par­tial de­riv­a­tive of the like­li­hood func­tion with re­spect to each one of the pa­ra­me­ter­s. You can ref­er­ence my ear­li­er post ti­tled <a href="/2018/11/15/normal-and-laplace-distributions/"><em>Nor­mal and Laplace Dis­tri­b­u­tions</em></a> for a deep­er ex­pla­na­tion. But what if tak­ing the de­riv­a­tive is dif­fi­cult or im­pos­si­ble to do? Con­sid­er the like­li­hood func­tion for the gen­er­al­ized nor­mal dis­tri­b­u­tion:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-16-latex-3225080871.svg" alt="Figure 16" height="50"></figure><p>To fit the gen­er­al­ized nor­mal dis­tri­b­u­tion to an ob­served set of data, we need to find the pa­ra­me­ter val­ues that max­i­mize this func­tion. In­stead of com­ing up with an an­a­lyt­i­cal so­lu­tion, we can use a nu­mer­i­cal op­ti­miza­tion method. Tak­ing this ap­proach, we need to come up with a cost func­tion that our op­ti­miza­tion method can eval­u­ate it­er­a­tive­ly. Here is the cost func­tion that we will use in the ex­am­ples in the fol­low­ing sec­tion­s:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-17-latex-1451409283.svg" alt="Figure 17" height="50"></figure><p>This is just the nega­tion of the log­a­rithm of the like­li­hood func­tion. We want to take the neg­a­tive in this case be­cause, in the ex­am­ples in the fol­low­ing sec­tion­s, we’re go­ing to use an im­ple­men­ta­tion of the Nelder–Mead op­ti­miza­tion method that finds min­i­mums in­stead of max­i­mum­s. And by us­ing the log­a­rithm of the like­li­hood func­tion, we can avoid deal­ing with num­bers that are too large for a dou­ble-pre­ci­sion float­ing-point num­ber. Since our cho­sen op­ti­miza­tion method re­quires an ini­tial guess of the pa­ra­me­ter val­ues, we can start by giv­ing the shape pa­ra­me­ter a val­ue of two:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-18-latex-0393582360.svg" alt="Figure 18" height="18"></figure><p>This would im­ply a nor­mal dis­tri­b­u­tion, so we might al­so set the ini­tial guess for the lo­ca­tion and scale pa­ra­me­ters ac­cord­ing­ly:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-19-latex-0880764277.svg" alt="Figure 19" height="59"></figure><p>This puts our ini­tial pa­ra­me­ter es­ti­mates in the right ball­park. Our nu­mer­i­cal op­ti­miza­tion al­go­rithm can then it­er­a­tive­ly find in­creas­ing­ly bet­ter and bet­ter es­ti­mates un­til some ter­mi­nat­ing cri­te­ri­on is met. If we know that the dis­tri­b­u­tion of our da­ta more close­ly re­sem­bles that of a Laplace dis­tri­b­u­tion—as with the da­ta stud­ied in my post ti­tled <a href="/2019/01/26/the-distribution-of-price-fluctuations/"><em>The Dis­tri­b­u­tion of Price Fluc­tu­a­tions</em></a>—we might choose an ini­tial guess based on the pa­ra­me­ters fit­ted to a Laplace dis­tri­b­u­tion in­stead. The nu­mer­i­cal ap­prox­i­ma­tion should come out rough­ly the same in ei­ther case.</p><h2 id="microsoft-stock-prices">Mi­crosoft Stock Prices</h2><p>Now let’s take a look at some ex­am­ples of fit­ting the gen­er­al­ized nor­mal dis­tri­b­u­tion to some da­ta in the wild. For this ex­am­ple, we’ll use the his­tor­i­cal stock prices of Mi­crosoft Cor­po­ra­tion go­ing back to 1986. We’ll take the log­a­rithm of the dai­ly clos­ing prices, com­pute the first dif­fer­ences, and then put the da­ta in a his­togram. The fol­low­ing charts show the his­togram over­laid with the fit­ted nor­mal, Laplace, and gen­er­al­ized nor­mal den­si­ty func­tion­s, re­spec­tive­ly:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-20-fitted-MSFT-N.svg" alt="Figure 20" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-21-fitted-MSFT-L.svg" alt="Figure 21" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-22-fitted-MSFT-G.svg" alt="Figure 22" height="405" width="720"></figure><p>The fit­ted gen­er­al­ized nor­mal dis­tri­b­u­tion has the fol­low­ing shape pa­ra­me­ter:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-23-latex-1490642935.svg" alt="Figure 23" height="18"></figure><p>This val­ue is very close to one, mean­ing that the shape of the den­si­ty func­tion is very close to that of the Laplace dis­tri­b­u­tion. Eye­balling the charts above, you can’t re­al­ly tell the dif­fer­ence be­tween the fit­ted Laplace den­si­ty func­tion and the fit­ted gen­er­al­ized nor­mal den­si­ty func­tion.</p><h2 id="bitcoin-prices">Bit­coin Prices</h2><p>Let’s do an­oth­er ex­am­ple. This one us­es his­tor­i­cal bit­coin prices go­ing back to 2011. Like be­fore, we’ll take the log­a­rithm of the dai­ly prices, com­pute the first dif­fer­ences, and then put the da­ta in a his­togram. The fol­low­ing charts show the his­togram over­laid with the fit­ted nor­mal, Laplace, and gen­er­al­ized nor­mal den­si­ty func­tion­s, re­spec­tive­ly:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-24-fitted-BTCUSD-N.svg" alt="Figure 24" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-25-fitted-BTCUSD-L.svg" alt="Figure 25" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-26-fitted-BTCUSD-G.svg" alt="Figure 26" height="405" width="720"></figure><p>The fit­ted gen­er­al­ized nor­mal dis­tri­b­u­tion has the fol­low­ing shape pa­ra­me­ter:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-27-latex-1253145037.svg" alt="Figure 27" height="18"></figure><p>This is a bit small­er than the shape pa­ra­me­ter that would con­form to a Laplace dis­tri­b­u­tion. As you can see in the charts above, the fit­ted den­si­ty func­tion for the gen­er­al­ized nor­mal dis­tri­b­u­tion is taller and thin­ner than the den­si­ty func­tion for the Laplace dis­tri­b­u­tion.</p><h2 id="natural-gas-prices">Nat­ural Gas Prices</h2><p>For the third ex­am­ple, let’s use the his­tor­i­cal prices of a nat­ural gas ET­F. As with the pre­vi­ous two ex­am­ples, we’ll take the log­a­rithm of the dai­ly price quotes, com­pute the first dif­fer­ences, and then put the da­ta in a his­togram. The fol­low­ing charts show the his­togram over­laid with the fit­ted nor­mal, Laplace, and gen­er­al­ized nor­mal den­si­ty func­tion­s, re­spec­tive­ly:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-28-fitted-UNG-N.svg" alt="Figure 28" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-29-fitted-UNG-L.svg" alt="Figure 29" height="405" width="720"></figure><figure class="fig-chart" style="padding-top: 56.25%;"><img src="./2022/07/07/generalized-normal-distributions/fig-30-fitted-UNG-G.svg" alt="Figure 30" height="405" width="720"></figure><p>The fit­ted gen­er­al­ized nor­mal dis­tri­b­u­tion has the fol­low­ing shape pa­ra­me­ter:</p><figure class="fig-latex"><img src="./2022/07/07/generalized-normal-distributions/fig-31-latex-1790454350.svg" alt="Figure 31" height="18"></figure><p>This val­ue is a bit larg­er than the shape pa­ra­me­ter that would con­form to a Laplace dis­tri­b­u­tion. In con­trast to the pre­vi­ous ex­am­ple, the fit­ted den­si­ty func­tion for the gen­er­al­ized nor­mal dis­tri­b­u­tion in this ex­am­ple is short­er and wider than the den­si­ty func­tion for the Laplace dis­tri­b­u­tion.</p><h2 id="other-distributions">Oth­er Dis­tri­b­u­tions</h2><p>For the da­ta sets used in the ex­am­ples above (and for sim­i­lar da­ta sets rep­re­sent­ing price fluc­tu­a­tions in fi­nan­cial mar­ket­s), there is no doubt that fit­ting the da­ta to a gen­er­al­ized nor­mal dis­tri­b­u­tion gives bet­ter re­sults than fit­ting the da­ta to a Laplace dis­tri­b­u­tion. But I am not con­vinced that this is the best kind of prob­a­bil­i­ty dis­tri­b­u­tion to use for mod­el­ing this type of data. In each of the ex­am­ples above, the peak of the dis­tri­b­u­tion im­plied by the his­togram seems to be much more round­ed than the den­si­ty func­tion of the fit­ted gen­er­al­ized nor­mal dis­tri­b­u­tion. Per­haps a <a href="https://en.wikipedia.org/wiki/Cauchy_distribution">Cauchy dis­tri­b­u­tion</a> might be a bet­ter al­ter­na­tive. And per­haps the nu­mer­i­cal tech­niques used here could open the door to ex­plor­ing the use of <a href="https://en.wikipedia.org/wiki/Stable_distribution">oth­er types</a> of prob­a­bil­i­ty dis­tri­b­u­tions as well.</p><p class="nojustify"><a href="https://github.com/jkillingsworth/jkillingsworth.com/tree/master/src/2022-07-07-generalized-normal-distributions">Ac­com­pa­ny­ing source code is avail­able on GitHub.</a></p><footer><time datetime="2022-07-07">July 7, 2022</time></footer></article><section class="comments"><header><h2>Com­ments</h2></header><script>
    var disqus_config = function () {
      this.page.url = "https://jkillingsworth.com/2022/07/07/generalized-normal-distributions/";
      this.page.title = "Generalized Normal Distributions";
      this.page.identifier = "/2022/07/07/generalized-normal-distributions/";
    };
    function disqus_show() {
      var d = document, s = d.createElement("script");
      s.src = "https://jkillingsworth.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    }
    function anchor_blur() {
      var a = document.getElementById("comments");
      a.innerText = "Comments";
      a.blur();
    }
    function disqus() {
      disqus_show();
      anchor_blur();
    }
  </script><a href="javascript:disqus();" id="comments" class="button">Show comments</a><div id="disqus_thread"></div><noscript> Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></section></main><aside class="sidebar"><header><h1>Sidebar</h1></header><section class="social-media"><header><h2>Social Media</h2></header><ul><li><a href="https://www.linkedin.com/in/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M417.2 64H96.8C79.3 64 64 76.6 64 93.9V415c0 17.4 15.3 32.9 32.8 32.9h320.3c17.6 0 30.8-15.6 30.8-32.9V93.9C448 76.6 434.7 64 417.2 64zM183 384h-55V213h55v171zm-25.6-197h-.4c-17.6 0-29-13.1-29-29.5 0-16.7 11.7-29.5 29.7-29.5s29 12.7 29.4 29.5c0 16.4-11.4 29.5-29.7 29.5zM384 384h-55v-93.5c0-22.4-8-37.7-27.9-37.7-15.2 0-24.2 10.3-28.2 20.3-1.5 3.6-1.9 8.5-1.9 13.5V384h-55V213h55v23.8c8-11.4 20.5-27.8 49.6-27.8 36.1 0 63.4 23.8 63.4 75.1V384z"/></svg><span>LinkedIn</span></a></li><li><a href="https://github.com/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9 1.4.3 2.6.4 3.8.4 8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1-8.4 1.9-15.9 2.7-22.6 2.7-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1 10.5 0 20-3.4 25.6-6 2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8 0 0 1.6-.5 5-.5 8.1 0 26.4 3.1 56.6 24.1 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 30.2-21 48.5-24.1 56.6-24.1 3.4 0 5 .5 5 .5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5 1.2 0 2.6-.1 4-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z"/></svg><span>GitHub</span></a></li></ul></section></aside><footer> &copy; 2018&ndash;2022 Jim Killingsworth. All rights reserved. </footer></body></html>