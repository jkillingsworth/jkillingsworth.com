<!doctype html><html lang="en-US"><head><title>Normal and Laplace Distributions - Jim Killingsworth</title><meta charset="utf-8"/><meta name="referrer" content="no-referrer-when-downgrade"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="description" content="Iâ€™m interested in studying the Laplace distribution. I was once under the impression that price fluctuations in the financial markets were normally distributed. However, as I plan to show in a later post, stock prices seem to move up and down according to a Laplace distribution instead. Before analyzing any historical price data, I first want to lay some groundwork and compare the Laplace distribution to the normal distribution."/><base href="/"/><link rel="canonical" href="https://jkillingsworth.com/2018/11/15/normal-and-laplace-distributions/"/><link rel="icon" href="./static/favicon.ico" type="image/x-icon"/><link rel="icon" href="./static/favicon-256.jpg" sizes="256x256"/><link rel="preload" href="./static/fonts/open-sans-v27-latin-700.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v20-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v20-latin-italic.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/roboto-mono-v13-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="https://www.google-analytics.com/analytics.js" as="script"/><script src="https://www.googletagmanager.com/gtag/js?id=UA-114299226-1" async></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag("js", new Date());
  gtag("config", "UA-114299226-1", { "send_page_view": true });
</script><style>@font-face{font-display:swap;font-family:"Open Sans";font-style:normal;font-weight:700;src:local("Open Sans Bold"),local("OpenSans-Bold"),url(./static/fonts/open-sans-v27-latin-700.woff2) format("woff2"),url(./static/fonts/open-sans-v27-latin-700.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:normal;font-weight:400;src:local("Lora Regular"),local("Lora-Regular"),url(./static/fonts/lora-v20-latin-regular.woff2) format("woff2"),url(./static/fonts/lora-v20-latin-regular.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:italic;font-weight:400;src:local("Lora Italic"),local("Lora-Italic"),url(./static/fonts/lora-v20-latin-italic.woff2) format("woff2"),url(./static/fonts/lora-v20-latin-italic.woff) format("woff")}@font-face{font-display:swap;font-family:"Roboto Mono";font-style:normal;font-weight:400;src:local("Roboto Mono"),local("RobotoMono-Regular"),url(./static/fonts/roboto-mono-v13-latin-regular.woff2) format("woff2"),url(./static/fonts/roboto-mono-v13-latin-regular.woff) format("woff")}
/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:0.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace, monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}
html{box-sizing:border-box;overflow-y:scroll}*,*::before,*::after{box-sizing:inherit}body{font-family:"Lora", "Georgia", serif;font-weight:normal;background:#fff;color:#000;display:flex;flex-flow:row wrap;font-size:12pt;justify-content:space-between;line-height:1.5;margin:0 auto;width:90%}body>*{flex:100%}body>header{font-size:21pt;margin:10px 0}body>footer{border-top:3px solid gray;font-size:10pt;font-style:italic;padding:16px 0}header,nav,h1,h2{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}header a,nav a,h1 a,h2 a{color:inherit}a{color:blue;text-decoration:none}a:hover{color:blue;text-decoration:underline}strong{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}svg{fill:currentColor}.navmenu{border-top:3px solid gray;border-bottom:1px solid #ccc}.navmenu #toggle{float:right;height:24px;margin:4px 0;width:24px}.navmenu #toggle+label{color:transparent;cursor:pointer;display:block;padding:4px 0;position:relative;user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none}.navmenu #toggle+label::before{background:#fff;background-size:24px;content:"";float:right;height:24px;left:24px;position:relative;width:24px}.navmenu #toggle+label::after{content:"Menu";left:0;padding:0 16px;position:absolute}.navmenu #toggle+label{border-bottom:none}.navmenu #toggle+label::before{background-image:url("./static/chevron-down.svg")}.navmenu #toggle+label::after{color:#000}.navmenu #toggle~ul{height:0;visibility:hidden}.navmenu #toggle:checked+label{border-bottom:1px solid #e6e6e6}.navmenu #toggle:checked+label::before{background-image:url("./static/chevron-up.svg")}.navmenu #toggle:checked+label::after{color:gray}.navmenu #toggle:checked~ul{height:auto;visibility:visible}.navmenu ul{display:flex;flex-flow:column wrap;list-style-type:none;justify-content:flex-start;margin:0;overflow:hidden;padding:0}.navmenu ul>li{flex:none}.navmenu ul>li a{display:block;padding:4px 16px}.navmenu ul>li a:hover,.navmenu ul>li a:focus{background:gray;color:#fff}.content{max-width:720px}.content header,.content footer,.content h1,.content h2,.content p,.content ul,.content figure{margin:24px 0}.content h1{font-size:18pt}.content h2{font-size:12pt}.content footer{font-style:italic}.content p:last-of-type::after{clear:both;content:"";display:block}.content ul{padding-left:16px}.content ul>li{margin:12px 0}.content figure{max-width:90vw}.content figure>img{display:block}.content .fig-chart{padding-top:56.25%;page-break-inside:avoid;position:relative}.content .fig-chart>img{max-height:100%;max-width:100%;position:absolute;top:0}.content .fig-latex{overflow-x:auto}.content .fig-latex>img{margin:0 16px}.content .fig-pic-l>img,.content .fig-pic-r>img{margin:0 auto;max-width:100%;object-fit:cover}.content .button{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;background:#e6e6e6;color:inherit;display:block;margin:24px 0;padding:4px 0;text-align:center}.content .button:hover,.content .button:focus{background:gray;color:#fff}.content .message header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .message header>h1::first-letter{text-transform:uppercase}.content .message header>h1::after{content:":"}.content .message p{font-style:italic}.content .newpost header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .newpost header>h1::first-letter{text-transform:uppercase}.content .newpost header>h1::after{content:":"}.content .newpost header>h2{font-size:18pt}.content .newpost a.readmore::after{content:" \00bb"}.content .newpost a:not(.readmore):not(:hover){color:inherit}.content .oldpost{margin:24px 0}.content .oldpost header>h1{display:none}.content .archive ul>li time{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:none;font-size:10pt}.content .contact label,.content .contact input[type="submit"]{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;cursor:pointer;display:block;margin:16px 0}.content .contact label{margin-bottom:4px}.content .contact input[type="text"],.content .contact input[type="email"],.content .contact textarea{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;line-height:inherit;padding:4px;width:100%}.content .contact textarea{height:200px;max-width:100%;min-width:100%}.content .contact input[type="submit"]{padding:4px 40px}.content .comments{margin:24px 0 8px}.content .comments header>h2{display:none}.content .comments noscript{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;margin:-12px 0 24px}.sidebar header>h1{display:none}.sidebar header>h2{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0}.sidebar section{margin:24px 0}.sidebar section:first-of-type{margin-top:0}.sidebar .social-media ul{list-style:none;padding:0 0 0 16px}.sidebar .social-media ul>li a{display:inline-block}.sidebar .social-media ul>li a *{vertical-align:middle}.sidebar .social-media ul>li a span{margin:0 10px}.sidebar .social-media ul>li a svg{color:gray;height:48px;width:48px}.sidebar .social-media ul>li a:hover svg{color:inherit}.content p:not(.nojustify),.sidebar p:not(.nojustify){text-align:justify;word-spacing:-1px}.content p,.content ul,.sidebar p,.sidebar ul{line-height:1.667}@media only screen and (min-width: 600px){.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{max-width:720px}body>header{font-size:24pt}.navmenu #toggle{display:none}.navmenu #toggle+label{display:none}.navmenu #toggle~ul{height:auto;visibility:visible}.navmenu ul{flex-flow:row wrap}.navmenu ul>li a{padding:4px 32px}}@media only screen and (min-width: 1200px){body{column-gap:60px;max-width:1200px;min-width:1080px}body>header{text-align:center}.content{flex:auto;width:720px}.sidebar{flex:auto}.sidebar section:first-of-type{margin-top:40px}}@media only print{.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{display:block;margin:auto;width:125%}body>header{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0;text-align:left}.content figure{max-width:100%}.navmenu,.sidebar,.oldpost,.comments{display:none}}@page{margin:1in 1.25in}
</style></head><body><header><a href="./">Jim Killingsworth</a></header><nav class="navmenu"><input id="toggle" type="checkbox"/><label for="toggle">Enable menu</label><ul><li><a href="./"> Home </a></li><li><a href="./archive/"> Archive </a></li><li><a href="./about/"> About </a></li><li><a href="./contact/"> Contact </a></li></ul></nav><main class="content"><article><header><h1>NorÂ­mal and Laplace DisÂ­triÂ­bÂ­uÂ­tions</h1></header><p>Iâ€™m inÂ­terÂ­estÂ­ed in studyÂ­ing the Laplace disÂ­triÂ­bÂ­uÂ­tion. I was once unÂ­der the imÂ­presÂ­sion that price flucÂ­tuÂ­aÂ­tions in the fiÂ­nanÂ­cial marÂ­kets were norÂ­malÂ­ly disÂ­tribÂ­utÂ­ed. HowÂ­evÂ­er, as I plan to show in a <a href="/2019/01/26/the-distribution-of-price-fluctuations/">latÂ­er post</a>, stock prices seem to move up and down acÂ­cordÂ­ing to a Laplace disÂ­triÂ­bÂ­uÂ­tion inÂ­stead. BeÂ­fore anÂ­aÂ­lyzÂ­ing any hisÂ­torÂ­iÂ­cal price data, I first want to lay some groundÂ­work and comÂ­pare the Laplace disÂ­triÂ­bÂ­uÂ­tion to the norÂ­mal disÂ­triÂ­bÂ­uÂ­tion.</p><h2 id="the-normal-distribution">The NorÂ­mal DisÂ­triÂ­bÂ­uÂ­tion</h2><p>SupÂ­pose we have a conÂ­tinÂ­uÂ­ous ranÂ­dom variÂ­able whose posÂ­siÂ­ble valÂ­ues are disÂ­tribÂ­uted acÂ­cordÂ­ing to a norÂ­mal disÂ­triÂ­bÂ­uÂ­tion. The probÂ­aÂ­bilÂ­iÂ­ty denÂ­siÂ­ty funcÂ­tion is:</p><figure class="fig-latex"><img width="282" height="47" alt="Figure 1" src="./2018/11/15/normal-and-laplace-distributions/fig-01-latex-0044592290.svg"></figure><p>If we have some samÂ­ples of a ranÂ­dom variÂ­able that we exÂ­pect to have a norÂ­mal disÂ­triÂ­bÂ­uÂ­tion, we can esÂ­tiÂ­mate the paÂ­raÂ­meÂ­ters of the denÂ­siÂ­ty funcÂ­tion usÂ­ing the maxÂ­iÂ­mum likeÂ­liÂ­hood method deÂ­scribed in some of my <a href="/2018/10/11/least-squares-and-normal-distributions/#maximum-likelihood-estimation">preÂ­viÂ­ous posts</a>. Since itâ€™s more conÂ­veÂ­nient in this case, inÂ­stead of maxÂ­iÂ­mizÂ­ing the likeÂ­liÂ­hood funcÂ­tion, letâ€™s maxÂ­iÂ­mize the logÂ­aÂ­rithm of the likeÂ­liÂ­hood funcÂ­tion:</p><figure class="fig-latex"><img width="396" height="50" alt="Figure 2" src="./2018/11/15/normal-and-laplace-distributions/fig-02-latex-1696808577.svg"></figure><p>We want to know what valÂ­ues for the mean and stanÂ­dard deÂ­viÂ­aÂ­tion paÂ­raÂ­meÂ­ters have the highÂ­est posÂ­siÂ­ble likeÂ­liÂ­hood. To do that, we can figÂ­ure out where the deÂ­rivÂ­aÂ­tive of the log-likeÂ­liÂ­hood funcÂ­tion with reÂ­spect to each of the paÂ­raÂ­meÂ­ters is equal to zeÂ­ro. Here is the parÂ­tial deÂ­rivÂ­aÂ­tive of the log-likeÂ­liÂ­hood funcÂ­tion with reÂ­spect to the mean:</p><figure class="fig-latex"><img width="178" height="50" alt="Figure 3" src="./2018/11/15/normal-and-laplace-distributions/fig-03-latex-1879483077.svg"></figure><p>SetÂ­ting the parÂ­tial deÂ­rivÂ­aÂ­tive to zeÂ­ro and solvÂ­ing for the mean, we arÂ­rive at the folÂ­lowÂ­ing esÂ­tiÂ­matÂ­ed valÂ­ue:</p><figure class="fig-latex"><img width="91" height="50" alt="Figure 4" src="./2018/11/15/normal-and-laplace-distributions/fig-04-latex-2703679590.svg"></figure><p>Once we have the valÂ­ue for the mean, we can folÂ­low the same steps to solve for the stanÂ­dard deÂ­viÂ­aÂ­tion. Here is the parÂ­tial deÂ­rivÂ­aÂ­tive of the log-likeÂ­liÂ­hood funcÂ­tion with reÂ­spect to the stanÂ­dard deÂ­viÂ­aÂ­tion:</p><figure class="fig-latex"><img width="233" height="50" alt="Figure 5" src="./2018/11/15/normal-and-laplace-distributions/fig-05-latex-0003002515.svg"></figure><p>SetÂ­ting the parÂ­tial deÂ­rivÂ­aÂ­tive to zeÂ­ro and solvÂ­ing for the stanÂ­dard deÂ­viÂ­aÂ­tion, we get this esÂ­tiÂ­matÂ­ed valÂ­ue:</p><figure class="fig-latex"><img width="163" height="59" alt="Figure 6" src="./2018/11/15/normal-and-laplace-distributions/fig-06-latex-3366669245.svg"></figure><p>If you want to see a more deÂ­tailed breakÂ­down of the steps above, you can refÂ­erÂ­ence my post tiÂ­tled <a href="/2018/10/11/least-squares-and-normal-distributions/"><em>Least Squares and NorÂ­mal DisÂ­triÂ­bÂ­uÂ­tions</em></a>. As I menÂ­tioned in that post, the maxÂ­iÂ­mum likeÂ­liÂ­hood esÂ­tiÂ­maÂ­tor for the stanÂ­dard deÂ­viÂ­aÂ­tion can give an esÂ­tiÂ­mate that is too low for small samÂ­ple sizes. If usÂ­ing a limÂ­itÂ­ed samÂ­ple size, it might be a good idea to apÂ­ply <a href="https://en.wikipedia.org/wiki/Bessel%27s_correction">Besselâ€™s corÂ­recÂ­tion</a> to get a more acÂ­cuÂ­rate esÂ­tiÂ­mate.</p><h2 id="the-laplace-distribution">The Laplace DisÂ­triÂ­bÂ­uÂ­tion</h2><p>SupÂ­pose we have a conÂ­tinÂ­uÂ­ous ranÂ­dom variÂ­able whose posÂ­siÂ­ble valÂ­ues are disÂ­tribÂ­uted acÂ­cordÂ­ing to a Laplace disÂ­triÂ­bÂ­uÂ­tion. The probÂ­aÂ­bilÂ­iÂ­ty denÂ­siÂ­ty funcÂ­tion is:</p><figure class="fig-latex"><img width="242" height="42" alt="Figure 7" src="./2018/11/15/normal-and-laplace-distributions/fig-07-latex-2586650686.svg"></figure><p>If we have a set of samÂ­ples of a ranÂ­dom variÂ­able that we know to have a Laplace disÂ­triÂ­bÂ­uÂ­tion, we can esÂ­tiÂ­mate the paÂ­raÂ­meÂ­ters usÂ­ing the same apÂ­proach we took for esÂ­tiÂ­matÂ­ing the paÂ­raÂ­meÂ­ters of the norÂ­mal disÂ­triÂ­bÂ­uÂ­tion. We can use the maxÂ­iÂ­mum likeÂ­liÂ­hood method. Here is the log-likeÂ­liÂ­hood funcÂ­tion we want to maxÂ­iÂ­mize:</p><figure class="fig-latex"><img width="282" height="50" alt="Figure 8" src="./2018/11/15/normal-and-laplace-distributions/fig-08-latex-3117225177.svg"></figure><p>We want to know what valÂ­ues of the loÂ­caÂ­tion and scale paÂ­raÂ­meÂ­ters have the greatÂ­est likeÂ­liÂ­hood. The anÂ­aÂ­lytÂ­iÂ­cal apÂ­proach is to take the deÂ­rivÂ­aÂ­tive, set it to zeÂ­ro, and solve for the paÂ­raÂ­meÂ­terÂ­s. But conÂ­sidÂ­er the abÂ­solute valÂ­ue funcÂ­tion:</p><figure class="fig-latex"><img width="221" height="71" alt="Figure 9" src="./2018/11/15/normal-and-laplace-distributions/fig-09-latex-1153198036.svg"></figure><p>Itâ€™s a pieceÂ­wise funcÂ­tion. TakÂ­ing the deÂ­rivÂ­aÂ­tive of the log-likeÂ­liÂ­hood funcÂ­tion with reÂ­spect to the loÂ­caÂ­tion paÂ­raÂ­meÂ­ter can be a bit tricky beÂ­cause the abÂ­solute valÂ­ue funcÂ­tion, alÂ­though conÂ­tinÂ­uÂ­ous, is not difÂ­ferÂ­enÂ­tiable at all points:</p><figure class="fig-latex"><img width="279" height="71" alt="Figure 10" src="./2018/11/15/normal-and-laplace-distributions/fig-10-latex-1359067230.svg"></figure><p>To be more sucÂ­cincÂ­t, we can repÂ­reÂ­sent the deÂ­rivÂ­aÂ­tive of the abÂ­solute valÂ­ue funcÂ­tion usÂ­ing the sign funcÂ­tion:</p><figure class="fig-latex"><img width="246" height="43" alt="Figure 11" src="./2018/11/15/normal-and-laplace-distributions/fig-11-latex-3075603000.svg"></figure><p>The sign funcÂ­tion simÂ­ply reÂ­turns the sign of a valÂ­ue:</p><figure class="fig-latex"><img width="234" height="71" alt="Figure 12" src="./2018/11/15/normal-and-laplace-distributions/fig-12-latex-2685832662.svg"></figure><p>We can exÂ­press the parÂ­tial deÂ­rivÂ­aÂ­tive of the log-likeÂ­liÂ­hood funcÂ­tion with reÂ­spect to the loÂ­caÂ­tion paÂ­raÂ­meÂ­ter as:</p><figure class="fig-latex"><img width="268" height="50" alt="Figure 13" src="./2018/11/15/normal-and-laplace-distributions/fig-13-latex-3720773995.svg"></figure><p>This is reÂ­alÂ­ly just givÂ­ing us the numÂ­ber of samÂ­ples with a valÂ­ue greater than the loÂ­caÂ­tion paÂ­raÂ­meÂ­ter miÂ­nus the numÂ­ber of samÂ­ples with a valÂ­ue less than the loÂ­caÂ­tion paÂ­raÂ­meÂ­ter. Note alÂ­so that the deÂ­rivÂ­aÂ­tive is unÂ­deÂ­fined at points where the loÂ­caÂ­tion paÂ­raÂ­meÂ­ter equals the valÂ­ue of one of the samÂ­ples. While not adÂ­eÂ­quate for an anÂ­aÂ­lytÂ­iÂ­cal soÂ­luÂ­tion, this does proÂ­vide a clue that the best esÂ­tiÂ­mate is at or near the meÂ­diÂ­an valÂ­ue. Letâ€™s rank our samÂ­ples in asÂ­cendÂ­ing orÂ­der:</p><figure class="fig-latex"><img width="299" height="19" alt="Figure 14" src="./2018/11/15/normal-and-laplace-distributions/fig-14-latex-0472275132.svg"></figure><p>Letâ€™s alÂ­so choose a midÂ­dle valÂ­ue that is about halfway beÂ­tween the first and last samÂ­ple in the orÂ­dered set. The exÂ­act valÂ­ue deÂ­pends on whether the toÂ­tal numÂ­ber of samÂ­ples is an even numÂ­ber or an odd numÂ­ber:</p><figure class="fig-latex"><img width="209" height="87" alt="Figure 15" src="./2018/11/15/normal-and-laplace-distributions/fig-15-latex-0164297596.svg"></figure><p>We can glean some inÂ­sights by lookÂ­ing at a plot of the likeÂ­liÂ­hood valÂ­ue for posÂ­siÂ­ble valÂ­ues of the loÂ­caÂ­tion paÂ­raÂ­meÂ­ter. When there is an even numÂ­ber of samÂ­ples, the likeÂ­liÂ­hood funcÂ­tion looks like this:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 16" src="./2018/11/15/normal-and-laplace-distributions/fig-16-log-likelihood-laplace-e.svg"></figure><p>NoÂ­tice that there is a range of posÂ­siÂ­ble valÂ­ues where the likeÂ­liÂ­hood is at a maxÂ­iÂ­mum when there is an even numÂ­ber of samÂ­ples. For an odd numÂ­ber of samÂ­ples, the likeÂ­liÂ­hood funcÂ­tion looks slightÂ­ly difÂ­ferÂ­enÂ­t:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 17" src="./2018/11/15/normal-and-laplace-distributions/fig-17-log-likelihood-laplace-o.svg"></figure><p>For an odd numÂ­ber of samÂ­ples, there is a sinÂ­gle point at which the likeÂ­liÂ­hood is maxÂ­iÂ­mized. By inÂ­specÂ­tion, we can conÂ­clude that the meÂ­diÂ­an valÂ­ue of our samÂ­ples has the highÂ­est likeÂ­liÂ­hood for the loÂ­caÂ­tion paÂ­raÂ­meÂ­ter:</p><figure class="fig-latex"><img width="267" height="73" alt="Figure 18" src="./2018/11/15/normal-and-laplace-distributions/fig-18-latex-0897005614.svg"></figure><p>If we have an even numÂ­ber of samÂ­ples, we just take the mean of the two meÂ­diÂ­an valÂ­ues. Once an esÂ­tiÂ­mate of the loÂ­caÂ­tion paÂ­raÂ­meÂ­ter is known, solvÂ­ing for the scale paÂ­raÂ­meÂ­ter is a bit easÂ­iÂ­er since there is an anÂ­aÂ­lytÂ­iÂ­cal soÂ­luÂ­tion. Here is the parÂ­tial deÂ­rivÂ­aÂ­tive of the log-likeÂ­liÂ­hood funcÂ­tion with reÂ­spect to the scale paÂ­raÂ­meÂ­ter:</p><figure class="fig-latex"><img width="216" height="50" alt="Figure 19" src="./2018/11/15/normal-and-laplace-distributions/fig-19-latex-3036695813.svg"></figure><p>SetÂ­ting the parÂ­tial deÂ­rivÂ­aÂ­tive to zeÂ­ro and solvÂ­ing for the scale paÂ­raÂ­meÂ­ter, we get the folÂ­lowÂ­ing esÂ­tiÂ­mate:</p><figure class="fig-latex"><img width="129" height="50" alt="Figure 20" src="./2018/11/15/normal-and-laplace-distributions/fig-20-latex-3489875293.svg"></figure><p>It think itâ€™s worth menÂ­tionÂ­ing here that this method of esÂ­tiÂ­matÂ­ing the paÂ­raÂ­meÂ­ters of a Laplace disÂ­triÂ­bÂ­uÂ­tion doesÂ­nâ€™t sit well with me. ChoosÂ­ing the meÂ­diÂ­an valÂ­ue for the loÂ­caÂ­tion paÂ­raÂ­meÂ­ter seems like a coarse apÂ­proach. In casÂ­es where there is a range of posÂ­siÂ­ble valÂ­ues for the loÂ­caÂ­tion, I wonÂ­der just how wide that range can be in pracÂ­tice. There might be othÂ­er esÂ­tiÂ­maÂ­tion techÂ­niques worth lookÂ­ing inÂ­to, but I want to see how well this one works with reÂ­al daÂ­ta beÂ­fore exÂ­plorÂ­ing alÂ­terÂ­naÂ­tives.</p><h2 id="comparison">ComÂ­parÂ­iÂ­son</h2><p>The norÂ­mal disÂ­triÂ­bÂ­uÂ­tion and the Laplace disÂ­triÂ­bÂ­uÂ­tion are both symÂ­metÂ­riÂ­cal. The denÂ­siÂ­ty funcÂ­tions of each have a simÂ­iÂ­lar strucÂ­ture. And with a small numÂ­ber of samÂ­ples, it might be difÂ­fiÂ­cult to deÂ­terÂ­mine if a ranÂ­dom variÂ­able has a norÂ­mal disÂ­triÂ­bÂ­uÂ­tion or a Laplace disÂ­triÂ­bÂ­uÂ­tion. HowÂ­evÂ­er, there are some imÂ­porÂ­tant difÂ­ferÂ­ences that are best shown with an ilÂ­lusÂ­traÂ­tion:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 21" src="./2018/11/15/normal-and-laplace-distributions/fig-21-distributions-lin.svg"></figure><p>Both denÂ­siÂ­ty funcÂ­tions have the same baÂ­sic shape. The denÂ­siÂ­ty plot of the Laplace disÂ­triÂ­bÂ­uÂ­tion, howÂ­evÂ­er, is taller and skinÂ­nier in the midÂ­dle. It alÂ­so has fatÂ­ter tails than the norÂ­mal disÂ­triÂ­bÂ­uÂ­tion. I think those fat tails are worth takÂ­ing a closÂ­er look at. Here is the same chart with the denÂ­siÂ­ty plotÂ­ted on a logÂ­aÂ­rithÂ­mic scale:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 22" src="./2018/11/15/normal-and-laplace-distributions/fig-22-distributions-log.svg"></figure><p>NoÂ­tice the difÂ­ferÂ­ence in magÂ­niÂ­tude for valÂ­ues far from the midÂ­dle. The probÂ­aÂ­bilÂ­iÂ­ty of obÂ­servÂ­ing a valÂ­ue of a norÂ­malÂ­ly disÂ­tribÂ­uted ranÂ­dom variÂ­able far from the mean is quite smalÂ­l. The probÂ­aÂ­bilÂ­iÂ­ty of obÂ­servÂ­ing the same valÂ­ue, while still smalÂ­l, might be orÂ­ders of magÂ­niÂ­tude greater if the ranÂ­dom variÂ­able has a Laplace disÂ­triÂ­bÂ­uÂ­tion.</p><p class="nojustify"><a href="https://github.com/jkillingsworth/jkillingsworth.com/tree/master/src/2018-11-15-normal-and-laplace-distributions">AcÂ­comÂ­paÂ­nyÂ­ing source code is availÂ­able on GitHub.</a></p><footer><time datetime="2018-11-15">November 15, 2018</time></footer></article><section class="comments"><header><h2>ComÂ­ments</h2></header><script>
    var disqus_config = function () {
      this.page.url = "https://jkillingsworth.com/2018/11/15/normal-and-laplace-distributions/";
      this.page.title = "Normal and Laplace Distributions";
      this.page.identifier = "/2018/11/15/normal-and-laplace-distributions/";
    };
    function disqus_show() {
      var d = document, s = d.createElement("script");
      s.src = "https://jkillingsworth.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    }
    function anchor_blur() {
      var a = document.getElementById("comments");
      a.innerText = "Comments";
      a.blur();
    }
    function disqus() {
      disqus_show();
      anchor_blur();
    }
  </script><a href="javascript:disqus();" id="comments" class="button">Show comments</a><div id="disqus_thread"></div><noscript> Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></section></main><aside class="sidebar"><header><h1>Sidebar</h1></header><section class="social-media"><header><h2>Social Media</h2></header><ul><li><a href="https://www.linkedin.com/in/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M417.2 64H96.8C79.3 64 64 76.6 64 93.9V415c0 17.4 15.3 32.9 32.8 32.9h320.3c17.6 0 30.8-15.6 30.8-32.9V93.9C448 76.6 434.7 64 417.2 64zM183 384h-55V213h55v171zm-25.6-197h-.4c-17.6 0-29-13.1-29-29.5 0-16.7 11.7-29.5 29.7-29.5s29 12.7 29.4 29.5c0 16.4-11.4 29.5-29.7 29.5zM384 384h-55v-93.5c0-22.4-8-37.7-27.9-37.7-15.2 0-24.2 10.3-28.2 20.3-1.5 3.6-1.9 8.5-1.9 13.5V384h-55V213h55v23.8c8-11.4 20.5-27.8 49.6-27.8 36.1 0 63.4 23.8 63.4 75.1V384z"/></svg><span>LinkedIn</span></a></li><li><a href="https://github.com/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9 1.4.3 2.6.4 3.8.4 8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1-8.4 1.9-15.9 2.7-22.6 2.7-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1 10.5 0 20-3.4 25.6-6 2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8 0 0 1.6-.5 5-.5 8.1 0 26.4 3.1 56.6 24.1 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 30.2-21 48.5-24.1 56.6-24.1 3.4 0 5 .5 5 .5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5 1.2 0 2.6-.1 4-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z"/></svg><span>GitHub</span></a></li></ul></section></aside><footer> &copy; 2018&ndash;2022 Jim Killingsworth. All rights reserved. </footer></body></html>