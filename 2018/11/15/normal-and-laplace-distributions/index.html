<!doctype html><html lang="en-US"><head><title>Normal and Laplace Distributions - Jim Killingsworth</title><meta charset="utf-8"/><meta name="referrer" content="no-referrer-when-downgrade"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="description" content="I’m interested in studying the Laplace distribution. I was once under the impression that price fluctuations in the financial markets were normally distributed. However, as I plan to show in a later post, stock prices seem to move up and down according to a Laplace distribution instead. Before analyzing any historical price data, I first want to lay some groundwork and compare the Laplace distribution to the normal distribution."/><base href="/"/><link rel="canonical" href="https://jkillingsworth.com/2018/11/15/normal-and-laplace-distributions/"/><link rel="icon" href="./static/favicon.ico" type="image/x-icon"/><link rel="icon" href="./static/favicon-256.jpg" sizes="256x256"/><link rel="preload" href="./static/fonts/open-sans-v27-latin-700.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v20-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/lora-v20-latin-italic.woff2" as="font" crossorigin/><link rel="preload" href="./static/fonts/roboto-mono-v13-latin-regular.woff2" as="font" crossorigin/><link rel="preload" href="https://www.google-analytics.com/analytics.js" as="script"/><script src="https://www.googletagmanager.com/gtag/js?id=UA-114299226-1" async></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag("js", new Date());
  gtag("config", "UA-114299226-1", { "send_page_view": true });
</script><style>@font-face{font-display:swap;font-family:"Open Sans";font-style:normal;font-weight:700;src:local("Open Sans Bold"),local("OpenSans-Bold"),url(./static/fonts/open-sans-v27-latin-700.woff2) format("woff2"),url(./static/fonts/open-sans-v27-latin-700.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:normal;font-weight:400;src:local("Lora Regular"),local("Lora-Regular"),url(./static/fonts/lora-v20-latin-regular.woff2) format("woff2"),url(./static/fonts/lora-v20-latin-regular.woff) format("woff")}@font-face{font-display:swap;font-family:"Lora";font-style:italic;font-weight:400;src:local("Lora Italic"),local("Lora-Italic"),url(./static/fonts/lora-v20-latin-italic.woff2) format("woff2"),url(./static/fonts/lora-v20-latin-italic.woff) format("woff")}@font-face{font-display:swap;font-family:"Roboto Mono";font-style:normal;font-weight:400;src:local("Roboto Mono"),local("RobotoMono-Regular"),url(./static/fonts/roboto-mono-v13-latin-regular.woff2) format("woff2"),url(./static/fonts/roboto-mono-v13-latin-regular.woff) format("woff")}
/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:0.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace, monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}
html{box-sizing:border-box;overflow-y:scroll}*,*::before,*::after{box-sizing:inherit}body{font-family:"Lora", "Georgia", serif;font-weight:normal;background:#fff;color:#000;display:flex;flex-flow:row wrap;font-size:12pt;justify-content:space-between;line-height:1.5;margin:0 auto;width:90%}body>*{flex:100%}body>header{font-size:21pt;margin:10px 0}body>footer{border-top:3px solid gray;font-size:10pt;font-style:italic;padding:16px 0}header,nav,h1,h2{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}header a,nav a,h1 a,h2 a{color:inherit}a{color:blue;text-decoration:none}a:hover{color:blue;text-decoration:underline}strong{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold}svg{fill:currentColor}.navmenu{border-top:3px solid gray;border-bottom:1px solid #ccc}.navmenu #toggle{float:right;height:24px;margin:4px 0;width:24px}.navmenu #toggle+label{color:transparent;cursor:pointer;display:block;padding:4px 0;position:relative;user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none}.navmenu #toggle+label::before{background:#fff;background-size:24px;content:"";float:right;height:24px;left:24px;position:relative;width:24px}.navmenu #toggle+label::after{content:"Menu";left:0;padding:0 16px;position:absolute}.navmenu #toggle+label{border-bottom:none}.navmenu #toggle+label::before{background-image:url("./static/chevron-down.svg")}.navmenu #toggle+label::after{color:#000}.navmenu #toggle~ul{height:0;visibility:hidden}.navmenu #toggle:checked+label{border-bottom:1px solid #e6e6e6}.navmenu #toggle:checked+label::before{background-image:url("./static/chevron-up.svg")}.navmenu #toggle:checked+label::after{color:gray}.navmenu #toggle:checked~ul{height:auto;visibility:visible}.navmenu ul{display:flex;flex-flow:column wrap;list-style-type:none;justify-content:flex-start;margin:0;overflow:hidden;padding:0}.navmenu ul>li{flex:none}.navmenu ul>li a{display:block;padding:4px 16px}.navmenu ul>li a:hover,.navmenu ul>li a:focus{background:gray;color:#fff}.content{max-width:720px}.content header,.content footer,.content h1,.content h2,.content p,.content ul,.content figure{margin:24px 0}.content h1{font-size:18pt}.content h2{font-size:12pt}.content footer{font-style:italic}.content p:last-of-type::after{clear:both;content:"";display:block}.content ul{padding-left:16px}.content ul>li{margin:12px 0}.content figure{max-width:90vw}.content figure>img{display:block}.content .fig-chart{padding-top:56.25%;page-break-inside:avoid;position:relative}.content .fig-chart>img{max-height:100%;max-width:100%;position:absolute;top:0}.content .fig-latex{overflow-x:auto}.content .fig-latex>img{margin:0 16px}.content .fig-pic-l>img,.content .fig-pic-r>img{margin:0 auto;max-width:100%;object-fit:cover}.content .button{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;background:#e6e6e6;color:inherit;display:block;margin:24px 0;padding:4px 0;text-align:center}.content .button:hover,.content .button:focus{background:gray;color:#fff}.content .message header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .message header>h1::first-letter{text-transform:uppercase}.content .message header>h1::after{content:":"}.content .message p{font-style:italic}.content .newpost header>h1{background:#ff0;display:inline-block;font-size:12pt;margin:0;text-transform:lowercase}.content .newpost header>h1::first-letter{text-transform:uppercase}.content .newpost header>h1::after{content:":"}.content .newpost header>h2{font-size:18pt}.content .newpost a.readmore::after{content:" \00bb"}.content .newpost a:not(.readmore):not(:hover){color:inherit}.content .oldpost{margin:24px 0}.content .oldpost header>h1{display:none}.content .archive ul>li time{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:none;font-size:10pt}.content .contact label,.content .contact input[type="submit"]{font-family:"Open Sans", "Verdana", sans-serif;font-weight:bold;cursor:pointer;display:block;margin:16px 0}.content .contact label{margin-bottom:4px}.content .contact input[type="text"],.content .contact input[type="email"],.content .contact textarea{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;line-height:inherit;padding:4px;width:100%}.content .contact textarea{height:200px;max-width:100%;min-width:100%}.content .contact input[type="submit"]{padding:4px 40px}.content .comments{margin:24px 0 8px}.content .comments header>h2{display:none}.content .comments noscript{font-family:"Roboto Mono", "Consolas", "Menlo", monospace;font-weight:normal;display:block;font-size:10pt;margin:-12px 0 24px}.sidebar header>h1{display:none}.sidebar header>h2{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0}.sidebar section{margin:24px 0}.sidebar section:first-of-type{margin-top:0}.sidebar .social-media ul{list-style:none;padding:0 0 0 16px}.sidebar .social-media ul>li a{display:inline-block}.sidebar .social-media ul>li a *{vertical-align:middle}.sidebar .social-media ul>li a span{margin:0 10px}.sidebar .social-media ul>li a svg{color:gray;height:48px;width:48px}.sidebar .social-media ul>li a:hover svg{color:inherit}.content p:not(.nojustify),.sidebar p:not(.nojustify){text-align:justify;word-spacing:-1px}.content p,.content ul,.sidebar p,.sidebar ul{line-height:1.667}@media only screen and (min-width: 600px){.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{max-width:720px}body>header{font-size:24pt}.navmenu #toggle{display:none}.navmenu #toggle+label{display:none}.navmenu #toggle~ul{height:auto;visibility:visible}.navmenu ul{flex-flow:row wrap}.navmenu ul>li a{padding:4px 32px}}@media only screen and (min-width: 1200px){body{column-gap:60px;max-width:1200px;min-width:1080px}body>header{text-align:center}.content{flex:auto;width:720px}.sidebar{flex:auto}.sidebar section:first-of-type{margin-top:40px}}@media only print{.content ul{padding-left:40px}.content ul>li{margin:0}.content .fig-latex>img{margin:0 40px}.content .fig-pic-l>img{float:left;margin:0 24px 0 0}.content .fig-pic-r>img{float:right;margin:0 0 0 24px}.content .archive ul>li time{display:inline}body{display:block;margin:auto;width:125%}body>header{border-bottom:1px solid #ccc;border-top:3px solid gray;font-size:inherit;margin:0;padding:4px 0;text-align:left}.content figure{max-width:100%}.navmenu,.sidebar,.oldpost,.comments{display:none}}@page{margin:1in 1.25in}
</style></head><body><header><a href="./">Jim Killingsworth</a></header><nav class="navmenu"><input id="toggle" type="checkbox"/><label for="toggle">Enable menu</label><ul><li><a href="./"> Home </a></li><li><a href="./archive/"> Archive </a></li><li><a href="./about/"> About </a></li><li><a href="./contact/"> Contact </a></li></ul></nav><main class="content"><article><header><h1>Nor­mal and Laplace Dis­tri­b­u­tions</h1></header><p>I’m in­ter­est­ed in study­ing the Laplace dis­tri­b­u­tion. I was once un­der the im­pres­sion that price fluc­tu­a­tions in the fi­nan­cial mar­kets were nor­mal­ly dis­trib­ut­ed. How­ev­er, as I plan to show in a <a href="/2019/01/26/the-distribution-of-price-fluctuations/">lat­er post</a>, stock prices seem to move up and down ac­cord­ing to a Laplace dis­tri­b­u­tion in­stead. Be­fore an­a­lyz­ing any his­tor­i­cal price data, I first want to lay some ground­work and com­pare the Laplace dis­tri­b­u­tion to the nor­mal dis­tri­b­u­tion.</p><h2 id="the-normal-distribution">The Nor­mal Dis­tri­b­u­tion</h2><p>Sup­pose we have a con­tin­u­ous ran­dom vari­able whose pos­si­ble val­ues are dis­trib­uted ac­cord­ing to a nor­mal dis­tri­b­u­tion. The prob­a­bil­i­ty den­si­ty func­tion is:</p><figure class="fig-latex"><img width="282" height="47" alt="Figure 1" src="./2018/11/15/normal-and-laplace-distributions/fig-01-latex-0044592290.svg"></figure><p>If we have some sam­ples of a ran­dom vari­able that we ex­pect to have a nor­mal dis­tri­b­u­tion, we can es­ti­mate the pa­ra­me­ters of the den­si­ty func­tion us­ing the max­i­mum like­li­hood method de­scribed in some of my <a href="/2018/10/11/least-squares-and-normal-distributions/#maximum-likelihood-estimation">pre­vi­ous posts</a>. Since it’s more con­ve­nient in this case, in­stead of max­i­miz­ing the like­li­hood func­tion, let’s max­i­mize the log­a­rithm of the like­li­hood func­tion:</p><figure class="fig-latex"><img width="396" height="50" alt="Figure 2" src="./2018/11/15/normal-and-laplace-distributions/fig-02-latex-1696808577.svg"></figure><p>We want to know what val­ues for the mean and stan­dard de­vi­a­tion pa­ra­me­ters have the high­est pos­si­ble like­li­hood. To do that, we can fig­ure out where the de­riv­a­tive of the log-like­li­hood func­tion with re­spect to each of the pa­ra­me­ters is equal to ze­ro. Here is the par­tial de­riv­a­tive of the log-like­li­hood func­tion with re­spect to the mean:</p><figure class="fig-latex"><img width="178" height="50" alt="Figure 3" src="./2018/11/15/normal-and-laplace-distributions/fig-03-latex-1879483077.svg"></figure><p>Set­ting the par­tial de­riv­a­tive to ze­ro and solv­ing for the mean, we ar­rive at the fol­low­ing es­ti­mat­ed val­ue:</p><figure class="fig-latex"><img width="91" height="50" alt="Figure 4" src="./2018/11/15/normal-and-laplace-distributions/fig-04-latex-2703679590.svg"></figure><p>Once we have the val­ue for the mean, we can fol­low the same steps to solve for the stan­dard de­vi­a­tion. Here is the par­tial de­riv­a­tive of the log-like­li­hood func­tion with re­spect to the stan­dard de­vi­a­tion:</p><figure class="fig-latex"><img width="233" height="50" alt="Figure 5" src="./2018/11/15/normal-and-laplace-distributions/fig-05-latex-0003002515.svg"></figure><p>Set­ting the par­tial de­riv­a­tive to ze­ro and solv­ing for the stan­dard de­vi­a­tion, we get this es­ti­mat­ed val­ue:</p><figure class="fig-latex"><img width="163" height="59" alt="Figure 6" src="./2018/11/15/normal-and-laplace-distributions/fig-06-latex-3366669245.svg"></figure><p>If you want to see a more de­tailed break­down of the steps above, you can ref­er­ence my post ti­tled <a href="/2018/10/11/least-squares-and-normal-distributions/"><em>Least Squares and Nor­mal Dis­tri­b­u­tions</em></a>. As I men­tioned in that post, the max­i­mum like­li­hood es­ti­ma­tor for the stan­dard de­vi­a­tion can give an es­ti­mate that is too low for small sam­ple sizes. If us­ing a lim­it­ed sam­ple size, it might be a good idea to ap­ply <a href="https://en.wikipedia.org/wiki/Bessel%27s_correction">Bessel’s cor­rec­tion</a> to get a more ac­cu­rate es­ti­mate.</p><h2 id="the-laplace-distribution">The Laplace Dis­tri­b­u­tion</h2><p>Sup­pose we have a con­tin­u­ous ran­dom vari­able whose pos­si­ble val­ues are dis­trib­uted ac­cord­ing to a Laplace dis­tri­b­u­tion. The prob­a­bil­i­ty den­si­ty func­tion is:</p><figure class="fig-latex"><img width="242" height="42" alt="Figure 7" src="./2018/11/15/normal-and-laplace-distributions/fig-07-latex-2586650686.svg"></figure><p>If we have a set of sam­ples of a ran­dom vari­able that we know to have a Laplace dis­tri­b­u­tion, we can es­ti­mate the pa­ra­me­ters us­ing the same ap­proach we took for es­ti­mat­ing the pa­ra­me­ters of the nor­mal dis­tri­b­u­tion. We can use the max­i­mum like­li­hood method. Here is the log-like­li­hood func­tion we want to max­i­mize:</p><figure class="fig-latex"><img width="282" height="50" alt="Figure 8" src="./2018/11/15/normal-and-laplace-distributions/fig-08-latex-3117225177.svg"></figure><p>We want to know what val­ues of the lo­ca­tion and scale pa­ra­me­ters have the great­est like­li­hood. The an­a­lyt­i­cal ap­proach is to take the de­riv­a­tive, set it to ze­ro, and solve for the pa­ra­me­ter­s. But con­sid­er the ab­solute val­ue func­tion:</p><figure class="fig-latex"><img width="221" height="71" alt="Figure 9" src="./2018/11/15/normal-and-laplace-distributions/fig-09-latex-1153198036.svg"></figure><p>It’s a piece­wise func­tion. Tak­ing the de­riv­a­tive of the log-like­li­hood func­tion with re­spect to the lo­ca­tion pa­ra­me­ter can be a bit tricky be­cause the ab­solute val­ue func­tion, al­though con­tin­u­ous, is not dif­fer­en­tiable at all points:</p><figure class="fig-latex"><img width="279" height="71" alt="Figure 10" src="./2018/11/15/normal-and-laplace-distributions/fig-10-latex-1359067230.svg"></figure><p>To be more suc­cinc­t, we can rep­re­sent the de­riv­a­tive of the ab­solute val­ue func­tion us­ing the sign func­tion:</p><figure class="fig-latex"><img width="246" height="43" alt="Figure 11" src="./2018/11/15/normal-and-laplace-distributions/fig-11-latex-3075603000.svg"></figure><p>The sign func­tion sim­ply re­turns the sign of a val­ue:</p><figure class="fig-latex"><img width="234" height="71" alt="Figure 12" src="./2018/11/15/normal-and-laplace-distributions/fig-12-latex-2685832662.svg"></figure><p>We can ex­press the par­tial de­riv­a­tive of the log-like­li­hood func­tion with re­spect to the lo­ca­tion pa­ra­me­ter as:</p><figure class="fig-latex"><img width="268" height="50" alt="Figure 13" src="./2018/11/15/normal-and-laplace-distributions/fig-13-latex-3720773995.svg"></figure><p>This is re­al­ly just giv­ing us the num­ber of sam­ples with a val­ue greater than the lo­ca­tion pa­ra­me­ter mi­nus the num­ber of sam­ples with a val­ue less than the lo­ca­tion pa­ra­me­ter. Note al­so that the de­riv­a­tive is un­de­fined at points where the lo­ca­tion pa­ra­me­ter equals the val­ue of one of the sam­ples. While not ad­e­quate for an an­a­lyt­i­cal so­lu­tion, this does pro­vide a clue that the best es­ti­mate is at or near the me­di­an val­ue. Let’s rank our sam­ples in as­cend­ing or­der:</p><figure class="fig-latex"><img width="299" height="19" alt="Figure 14" src="./2018/11/15/normal-and-laplace-distributions/fig-14-latex-0472275132.svg"></figure><p>Let’s al­so choose a mid­dle val­ue that is about halfway be­tween the first and last sam­ple in the or­dered set. The ex­act val­ue de­pends on whether the to­tal num­ber of sam­ples is an even num­ber or an odd num­ber:</p><figure class="fig-latex"><img width="209" height="87" alt="Figure 15" src="./2018/11/15/normal-and-laplace-distributions/fig-15-latex-0164297596.svg"></figure><p>We can glean some in­sights by look­ing at a plot of the like­li­hood val­ue for pos­si­ble val­ues of the lo­ca­tion pa­ra­me­ter. When there is an even num­ber of sam­ples, the like­li­hood func­tion looks like this:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 16" src="./2018/11/15/normal-and-laplace-distributions/fig-16-log-likelihood-laplace-e.svg"></figure><p>No­tice that there is a range of pos­si­ble val­ues where the like­li­hood is at a max­i­mum when there is an even num­ber of sam­ples. For an odd num­ber of sam­ples, the like­li­hood func­tion looks slight­ly dif­fer­en­t:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 17" src="./2018/11/15/normal-and-laplace-distributions/fig-17-log-likelihood-laplace-o.svg"></figure><p>For an odd num­ber of sam­ples, there is a sin­gle point at which the like­li­hood is max­i­mized. By in­spec­tion, we can con­clude that the me­di­an val­ue of our sam­ples has the high­est like­li­hood for the lo­ca­tion pa­ra­me­ter:</p><figure class="fig-latex"><img width="267" height="73" alt="Figure 18" src="./2018/11/15/normal-and-laplace-distributions/fig-18-latex-0897005614.svg"></figure><p>If we have an even num­ber of sam­ples, we just take the mean of the two me­di­an val­ues. Once an es­ti­mate of the lo­ca­tion pa­ra­me­ter is known, solv­ing for the scale pa­ra­me­ter is a bit eas­i­er since there is an an­a­lyt­i­cal so­lu­tion. Here is the par­tial de­riv­a­tive of the log-like­li­hood func­tion with re­spect to the scale pa­ra­me­ter:</p><figure class="fig-latex"><img width="216" height="50" alt="Figure 19" src="./2018/11/15/normal-and-laplace-distributions/fig-19-latex-3036695813.svg"></figure><p>Set­ting the par­tial de­riv­a­tive to ze­ro and solv­ing for the scale pa­ra­me­ter, we get the fol­low­ing es­ti­mate:</p><figure class="fig-latex"><img width="129" height="50" alt="Figure 20" src="./2018/11/15/normal-and-laplace-distributions/fig-20-latex-3489875293.svg"></figure><p>It think it’s worth men­tion­ing here that this method of es­ti­mat­ing the pa­ra­me­ters of a Laplace dis­tri­b­u­tion does­n’t sit well with me. Choos­ing the me­di­an val­ue for the lo­ca­tion pa­ra­me­ter seems like a coarse ap­proach. In cas­es where there is a range of pos­si­ble val­ues for the lo­ca­tion, I won­der just how wide that range can be in prac­tice. There might be oth­er es­ti­ma­tion tech­niques worth look­ing in­to, but I want to see how well this one works with re­al da­ta be­fore ex­plor­ing al­ter­na­tives.</p><h2 id="comparison">Com­par­i­son</h2><p>The nor­mal dis­tri­b­u­tion and the Laplace dis­tri­b­u­tion are both sym­met­ri­cal. The den­si­ty func­tions of each have a sim­i­lar struc­ture. And with a small num­ber of sam­ples, it might be dif­fi­cult to de­ter­mine if a ran­dom vari­able has a nor­mal dis­tri­b­u­tion or a Laplace dis­tri­b­u­tion. How­ev­er, there are some im­por­tant dif­fer­ences that are best shown with an il­lus­tra­tion:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 21" src="./2018/11/15/normal-and-laplace-distributions/fig-21-distributions-lin.svg"></figure><p>Both den­si­ty func­tions have the same ba­sic shape. The den­si­ty plot of the Laplace dis­tri­b­u­tion, how­ev­er, is taller and skin­nier in the mid­dle. It al­so has fat­ter tails than the nor­mal dis­tri­b­u­tion. I think those fat tails are worth tak­ing a clos­er look at. Here is the same chart with the den­si­ty plot­ted on a log­a­rith­mic scale:</p><figure class="fig-chart" style="padding-top: 56.25%;"><img width="720" height="405" alt="Figure 22" src="./2018/11/15/normal-and-laplace-distributions/fig-22-distributions-log.svg"></figure><p>No­tice the dif­fer­ence in mag­ni­tude for val­ues far from the mid­dle. The prob­a­bil­i­ty of ob­serv­ing a val­ue of a nor­mal­ly dis­trib­uted ran­dom vari­able far from the mean is quite smal­l. The prob­a­bil­i­ty of ob­serv­ing the same val­ue, while still smal­l, might be or­ders of mag­ni­tude greater if the ran­dom vari­able has a Laplace dis­tri­b­u­tion.</p><p class="nojustify"><a href="https://github.com/jkillingsworth/jkillingsworth.com/tree/master/src/2018-11-15-normal-and-laplace-distributions">Ac­com­pa­ny­ing source code is avail­able on GitHub.</a></p><footer><time datetime="2018-11-15">November 15, 2018</time></footer></article><section class="comments"><header><h2>Com­ments</h2></header><script>
    var disqus_config = function () {
      this.page.url = "https://jkillingsworth.com/2018/11/15/normal-and-laplace-distributions/";
      this.page.title = "Normal and Laplace Distributions";
      this.page.identifier = "/2018/11/15/normal-and-laplace-distributions/";
    };
    function disqus_show() {
      var d = document, s = d.createElement("script");
      s.src = "https://jkillingsworth.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    }
    function anchor_blur() {
      var a = document.getElementById("comments");
      a.innerText = "Comments";
      a.blur();
    }
    function disqus() {
      disqus_show();
      anchor_blur();
    }
  </script><a href="javascript:disqus();" id="comments" class="button">Show comments</a><div id="disqus_thread"></div><noscript> Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript></section></main><aside class="sidebar"><header><h1>Sidebar</h1></header><section class="social-media"><header><h2>Social Media</h2></header><ul><li><a href="https://www.linkedin.com/in/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M417.2 64H96.8C79.3 64 64 76.6 64 93.9V415c0 17.4 15.3 32.9 32.8 32.9h320.3c17.6 0 30.8-15.6 30.8-32.9V93.9C448 76.6 434.7 64 417.2 64zM183 384h-55V213h55v171zm-25.6-197h-.4c-17.6 0-29-13.1-29-29.5 0-16.7 11.7-29.5 29.7-29.5s29 12.7 29.4 29.5c0 16.4-11.4 29.5-29.7 29.5zM384 384h-55v-93.5c0-22.4-8-37.7-27.9-37.7-15.2 0-24.2 10.3-28.2 20.3-1.5 3.6-1.9 8.5-1.9 13.5V384h-55V213h55v23.8c8-11.4 20.5-27.8 49.6-27.8 36.1 0 63.4 23.8 63.4 75.1V384z"/></svg><span>LinkedIn</span></a></li><li><a href="https://github.com/jkillingsworth/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9 1.4.3 2.6.4 3.8.4 8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1-8.4 1.9-15.9 2.7-22.6 2.7-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1 10.5 0 20-3.4 25.6-6 2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8 0 0 1.6-.5 5-.5 8.1 0 26.4 3.1 56.6 24.1 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 30.2-21 48.5-24.1 56.6-24.1 3.4 0 5 .5 5 .5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5 1.2 0 2.6-.1 4-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z"/></svg><span>GitHub</span></a></li></ul></section></aside><footer> &copy; 2018&ndash;2022 Jim Killingsworth. All rights reserved. </footer></body></html>